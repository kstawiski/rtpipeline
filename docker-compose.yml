version: '3.8'

services:
  # Main rtpipeline service with GPU support (DEFAULT)
  rtpipeline:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BUILD_DATE: ${BUILD_DATE:-$(date -u +'%Y-%m-%dT%H:%M:%SZ')}
    image: kstawiski/rtpipeline:latest
    container_name: rtpipeline
    hostname: rtpipeline
    # Run as non-root user (UID 1000) to match host permissions
    user: "1000:1000"
    volumes:
      - ./Input:/data/input:rw
      - ./Output:/data/output:rw
      - ./Logs:/data/logs:rw

      # TotalSegmentator weights are bundled in the image - no need to mount
      # Uncomment below ONLY if you need to use newer weights than in the image:
      # - ./totalseg_weights:/home/rtpipeline/.totalsegmentator:rw

      - ./Uploads:/data/uploads:rw
      # Code mounted read-only for security
      - ./Code:/app/Code:ro
      - ./rtpipeline:/app/rtpipeline:ro
    ports:
      - "8080:8080"
    environment:
      - PYTHONPATH=/app
      - NUMBA_CACHE_DIR=/tmp/cache
      - MPLCONFIGDIR=/tmp/cache
      - CONDA_DIR=/opt/conda
      - PATH=/opt/conda/bin:$PATH
      # nnUNet environment paths (required for TotalSegmentator)
      - nnUNet_results=/home/rtpipeline/.totalsegmentator/nnunet/results
      - nnUNet_raw=/home/rtpipeline/.totalsegmentator/nnunet/raw
      - nnUNet_preprocessed=/home/rtpipeline/.totalsegmentator/nnunet/preprocessed
      # Timeouts for preventing hangs
      - TOTALSEG_TIMEOUT=3600
      - DCM2NIIX_TIMEOUT=300
      - RTPIPELINE_RADIOMICS_TASK_TIMEOUT=600
      # TotalSegmentator parallelism (avoid spawning issues in container)
      - TOTALSEG_NUM_PROCESSES_PREPROCESSING=1
      - TOTALSEG_NUM_PROCESSES_SEGMENTATION_EXPORT=1
      - TOTALSEG_FORCE_TORCH_NUM_THREADS=1
      - TOTALSEG_PRELOAD_WEIGHTS=1
      # PyTorch threading and memory control - use num_cores - 1 for optimal GPU parallelism
      - OMP_NUM_THREADS=8
      - MKL_NUM_THREADS=8
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - PORT=8080
      - DEBUG=false
    working_dir: /app
    command: >
      bash -c "
        cd /app/webui &&
        python app.py
      "
    # Security hardening
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
      - SYS_PTRACE
    # Resource limits - maximize CPU usage (num_cores - 1 = 23)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          cpus: '23.0'
          memory: 48G
    # Increased shm_size for TotalSegmentator/PyTorch (prevents container hangs)
    shm_size: '8gb'
    restart: unless-stopped

  # CPU-only service
  rtpipeline-cpu:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BUILD_DATE: ${BUILD_DATE:-$(date -u +'%Y-%m-%dT%H:%M:%SZ')}
    image: kstawiski/rtpipeline:latest
    container_name: rtpipeline-cpu
    hostname: rtpipeline-cpu
    user: "1000:1000"
    volumes:
      - ./Input:/data/input:rw
      - ./Output:/data/output:rw
      - ./Logs:/data/logs:rw

      # TotalSegmentator weights are bundled in the image - no need to mount
      # Uncomment below ONLY if you need to use newer weights than in the image:
      # - ./totalseg_weights:/home/rtpipeline/.totalsegmentator:rw

      - ./Uploads:/data/uploads:rw
      - ./Code:/app/Code:ro
      - ./rtpipeline:/app/rtpipeline:ro
    ports:
      - "8080:8080"
    environment:
      - PYTHONPATH=/app
      - NUMBA_CACHE_DIR=/tmp/cache
      - MPLCONFIGDIR=/tmp/cache
      - CONDA_DIR=/opt/conda
      - PATH=/opt/conda/bin:$PATH
      # nnUNet environment paths (required for TotalSegmentator)
      - nnUNet_results=/home/rtpipeline/.totalsegmentator/nnunet/results
      - nnUNet_raw=/home/rtpipeline/.totalsegmentator/nnunet/raw
      - nnUNet_preprocessed=/home/rtpipeline/.totalsegmentator/nnunet/preprocessed
      # Timeouts for preventing hangs (longer for CPU mode)
      - TOTALSEG_TIMEOUT=7200
      - DCM2NIIX_TIMEOUT=300
      - RTPIPELINE_RADIOMICS_TASK_TIMEOUT=1200
      # TotalSegmentator parallelism (avoid spawning issues in container)
      - TOTALSEG_NUM_PROCESSES_PREPROCESSING=1
      - TOTALSEG_NUM_PROCESSES_SEGMENTATION_EXPORT=1
      - TOTALSEG_FORCE_TORCH_NUM_THREADS=1
      - TOTALSEG_PRELOAD_WEIGHTS=1
      # PyTorch threading control - use num_cores - 1 for optimal CPU mode parallelism
      - OMP_NUM_THREADS=23
      - MKL_NUM_THREADS=23
      - PORT=8080
      - DEBUG=false
    working_dir: /app
    command: >
      bash -c "
        cd /app/webui &&
        python app.py
      "
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - SYS_PTRACE
    deploy:
      resources:
        limits:
          cpus: '23.0'
          memory: 48G
        reservations:
          cpus: '4.0'
          memory: 8G
    # Increased shm_size for TotalSegmentator/PyTorch (prevents container hangs)
    shm_size: '8gb'
    restart: unless-stopped
    profiles:
      - cpu-only

networks:
  default:
    name: rtpipeline-network

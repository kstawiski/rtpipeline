{"record_format_version": 6, "code": "        import subprocess\n        job_threads = max(1, threads)\n        manifest_path = Path(output.manifest)\n        manifest_path.parent.mkdir(parents=True, exist_ok=True)\n        LOGS_DIR.mkdir(parents=True, exist_ok=True)\n        skip_existing = False\n        if manifest_path.exists():\n            try:\n                manifest_data = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n                course_entries = manifest_data.get(\"courses\", [])\n            except Exception:\n            except Exception:\n                course_entries = []\n            if course_entries:\n                missing_flags = []\n                for entry in course_entries:\n                    try:\n                        course_dir = Path(entry.get(\"path\", \"\"))\n                    except Exception:\n                    except Exception:\n                        missing_flags.append(entry)\n                        continue\n                    flag = course_dir / \".organized\"\n                    if not flag.exists():\n                        missing_flags.append(entry)\n                skip_existing = not missing_flags\n        if skip_existing:\n            log_path = Path(log[0])\n            log_path.parent.mkdir(parents=True, exist_ok=True)\n            log_path.write_text(\"Organize stage skipped (manifest already present).\\n\", encoding=\"utf-8\")\n            return\n        env = _rt_env()\n        cmd = [\n            sys.executable,\n            \"-m\",\n            \"rtpipeline.cli\",\n            \"--dicom-root\", str(DICOM_ROOT),\n            \"--outdir\", str(OUTPUT_DIR),\n            \"--logs\", str(LOGS_DIR),\n            \"--stage\", \"organize\",\n        cmd.extend(_max_worker_args(job_threads))\n        if CUSTOM_STRUCTURES_CONFIG:\n            cmd.extend([\"--custom-structures\", CUSTOM_STRUCTURES_CONFIG])\n        with open(log[0], \"w\") as logf:\n        with open(log[0], \"w\") as logf:\n            subprocess.run(cmd, check=True, stdout=logf, stderr=subprocess.STDOUT, env=env)\n        courses = []\n        for patient_id, course_id, course_path in _iter_course_dirs():\n            flag = course_sentinel_path(patient_id, course_id, \".organized\")\n            flag.parent.mkdir(parents=True, exist_ok=True)\n            flag.write_text(\"ok\\n\", encoding=\"utf-8\")\n            complexity = _estimate_course_complexity(course_path)\n            courses.append(\n            courses.append(\n                {\n                    \"patient\": patient_id,\n                    \"course\": course_id,\n                    \"path\": str(course_path),\n                    \"complexity\": complexity,\n        if PRIORITIZE_SHORT_COURSES:\n            courses.sort(key=lambda entry: (entry.get(\"complexity\", 0), entry[\"patient\"], entry[\"course\"]))\n        COURSE_META_DIR.mkdir(parents=True, exist_ok=True)\n        manifest_path.write_text(json.dumps({\"courses\": courses}, indent=2), encoding=\"utf-8\")\n", "rule": "organize_courses", "input": [], "log": ["/data/logs/stage_organize.log"], "params": [], "shellcmd": null, "incomplete": false, "starttime": null, "endtime": 1764075456.9706104, "job_hash": 8280893862001, "conda_env": null, "software_stack_hash": "d41d8cd98f00b204e9800998ecf8427e", "container_img_url": null, "input_checksums": {}}
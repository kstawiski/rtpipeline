{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# RTpipeline on Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kstawiski/rtpipeline/blob/main/rtpipeline_colab.ipynb)\n",
    "\n",
    "This notebook allows you to run the RTpipeline radiotherapy data processing system on Google Colab with GPU acceleration.\n",
    "\n",
    "## What This Pipeline Does\n",
    "\n",
    "RTpipeline processes DICOM radiotherapy data and generates:\n",
    "- ‚úÖ **Automatic segmentation** of 100+ organs using TotalSegmentator\n",
    "- ‚úÖ **DVH metrics** (dose-volume histograms)\n",
    "- ‚úÖ **Radiomics features** (150+ texture/shape features)\n",
    "- ‚úÖ **Radiomics robustness testing** (ICC/CoV stability analysis) - **NEW!**\n",
    "- ‚úÖ **Quality control reports**\n",
    "- ‚úÖ **Analysis-ready tables** for machine learning\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Google Colab account (free tier works, but GPU runtime recommended)\n",
    "- DICOM files (CT, RTPLAN, RTDOSE, RTSTRUCT)\n",
    "- ~10-30 minutes processing time per patient (GPU)\n",
    "- +10-30 minutes if robustness testing enabled\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö° Quick Start:** Run all cells in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1Ô∏è‚É£ Setup: Install Miniconda\n",
    "\n",
    "This cell installs Miniconda for managing conda environments (~2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check GPU availability\n",
    "echo \"=== GPU Check ===\"\n",
    "nvidia-smi || echo \"‚ö†Ô∏è No GPU detected. Pipeline will use CPU (slower).\"\n",
    "\n",
    "# Install system dependencies\n",
    "echo -e \"\\n=== Installing System Dependencies ===\"\n",
    "apt-get update -qq\n",
    "apt-get install -y -qq dcm2niix pigz > /dev/null\n",
    "\n",
    "# Install Miniconda if not already installed\n",
    "if [ ! -d \"/content/miniconda\" ]; then\n",
    "    echo -e \"\\n=== Installing Miniconda ===\"\n",
    "    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh\n",
    "    bash /tmp/miniconda.sh -b -p /content/miniconda\n",
    "    rm /tmp/miniconda.sh\n",
    "    echo \"‚úÖ Miniconda installed\"\n",
    "else\n",
    "    echo -e \"\\n=== Miniconda already installed ===\"\n",
    "fi\n",
    "\n",
    "# Initialize conda\n",
    "export PATH=\"/content/miniconda/bin:$PATH\"\n",
    "eval \"$(/content/miniconda/bin/conda shell.bash hook)\"\n",
    "conda init bash\n",
    "\n",
    "echo -e \"\\n=== Conda initialized ===\"\n",
    "echo \"Conda version: $(conda --version)\"\n",
    "\n",
    "echo -e \"\\n‚úÖ Setup complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1Ô∏è‚É£b Setup: Create Conda Environments\n",
    "\n",
    "This cell creates two separate conda environments to handle numpy version conflicts:\n",
    "- **rtpipeline**: TotalSegmentator (requires numpy>=2.0)\n",
    "- **rtpipeline-radiomics**: PyRadiomics (requires numpy=1.26.x)\n",
    "\n",
    "This takes ~5-10 minutes but only needs to be done once per session."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%bash\nexport PATH=\"/content/miniconda/bin:$PATH\"\neval \"$(/content/miniconda/bin/conda shell.bash hook)\"\n\n# Accept Anaconda Terms of Service for required channels\necho \"=== Accepting Anaconda Terms of Service ===\"\n# NOTE: The project's README.md (lines 397 and 627) recommends 'channel_priority strict'\n# to avoid environment inconsistencies. However, in Google Colab, we must use 'flexible'\n# to allow ToS acceptance and compatibility with Colab's pre-installed packages.\n# This may lead to package version conflicts, but is required for Colab to work.\nconda config --set channel_priority flexible\nif ! conda tos accept --channel defaults 2>&1; then\n    echo \"‚ö†Ô∏è ToS acceptance for defaults channel failed or already accepted\"\nfi\necho \"‚úÖ ToS accepted\"\necho \"\"\n\n# Check if repository is already cloned (needed for env files)\nif [ ! -d \"/content/rtpipeline\" ]; then\n    echo \"Cloning rtpipeline repository (needed for environment files)...\"\n    git clone -q https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n    echo \"‚úÖ Repository cloned\"\nfi\n\ncd /content/rtpipeline\n\necho \"=== Creating Conda Environments ===\"\necho \"\"\n\n# Create rtpipeline environment (for TotalSegmentator with numpy>=2.0)\nif conda env list | grep -q \"^rtpipeline \"; then\n    echo \"‚úÖ Environment 'rtpipeline' already exists\"\nelse\n    echo \"Creating 'rtpipeline' environment (TotalSegmentator, numpy>=2.0)...\"\n    conda env create -f envs/rtpipeline.yaml -q\n    echo \"‚úÖ Environment 'rtpipeline' created\"\nfi\n\necho \"\"\n\n# Create rtpipeline-radiomics environment (for pyradiomics with numpy=1.26.x)\nif conda env list | grep -q \"^rtpipeline-radiomics \"; then\n    echo \"‚úÖ Environment 'rtpipeline-radiomics' already exists\"\nelse\n    echo \"Creating 'rtpipeline-radiomics' environment (PyRadiomics, numpy=1.26.x)...\"\n    conda env create -f envs/rtpipeline-radiomics.yaml -q\n    echo \"‚úÖ Environment 'rtpipeline-radiomics' created\"\nfi\n\necho \"\"\necho \"=== Environment Setup Complete ===\"\necho \"\"\necho \"Available conda environments:\"\nconda env list\n\necho \"\"\necho \"Verifying numpy versions:\"\necho \"- rtpipeline:\"\nconda run -n rtpipeline python -c \"import numpy; print(f'  numpy {numpy.__version__}')\"\necho \"- rtpipeline-radiomics:\"\nconda run -n rtpipeline-radiomics python -c \"import numpy; print(f'  numpy {numpy.__version__}')\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone"
   },
   "source": [
    "## 2Ô∏è‚É£ Clone RTpipeline Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Clone repository\n",
    "if [ ! -d \"/content/rtpipeline\" ]; then\n",
    "    echo \"Cloning rtpipeline repository...\"\n",
    "    git clone https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n",
    "    echo \"‚úÖ Repository cloned\"\n",
    "else\n",
    "    echo \"‚úÖ Repository already exists\"\n",
    "fi\n",
    "\n",
    "cd /content/rtpipeline\n",
    "git pull origin main\n",
    "echo \"Repository updated to latest version\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## 3Ô∏è‚É£ Upload Your DICOM Files\n",
    "\n",
    "You have two options:\n",
    "\n",
    "### Option A: Upload from Google Drive\n",
    "\n",
    "Run this cell to mount your Google Drive, then access files from `/content/drive/MyDrive/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n‚úÖ Google Drive mounted at /content/drive/MyDrive/\")\n",
    "print(\"\\nYour DICOM files should be in: /content/drive/MyDrive/your_dicom_folder/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_option_b"
   },
   "source": [
    "### Option B: Upload Files Directly\n",
    "\n",
    "Use the file browser on the left (üìÅ icon) to upload DICOM files to `/content/dicom_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dirs"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create directories\n",
    "mkdir -p /content/dicom_data\n",
    "mkdir -p /content/output\n",
    "mkdir -p /content/logs\n",
    "\n",
    "echo \"‚úÖ Directories created:\"\n",
    "echo \"  - /content/dicom_data (upload your DICOM files here)\"\n",
    "echo \"  - /content/output (results will be saved here)\"\n",
    "echo \"  - /content/logs (processing logs)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 4Ô∏è‚É£ Configure Pipeline\n",
    "\n",
    "Modify the settings below according to your needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_config"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ============ CONFIGURATION ============\n",
    "\n",
    "# DICOM directory (change if using Google Drive)\n",
    "DICOM_ROOT = \"/content/dicom_data\"\n",
    "# Example: DICOM_ROOT = \"/content/drive/MyDrive/my_dicom_folder\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"/content/output\"\n",
    "LOGS_DIR = \"/content/logs\"\n",
    "\n",
    "# Processing options\n",
    "USE_GPU = True  # Set to False if no GPU available\n",
    "ENABLE_RADIOMICS = True  # Extract radiomic features\n",
    "ENABLE_CT_CROPPING = False  # Crop CT to anatomical region\n",
    "CROP_REGION = \"pelvis\"  # Options: pelvis, thorax, abdomen, head_neck, brain\n",
    "\n",
    "# Advanced parallelization settings\n",
    "# NOTE: Colab uses cloud/network storage which is I/O-bound, not CPU-bound!\n",
    "# Lower worker counts often give better throughput by running more courses in parallel\n",
    "WORKERS = 2  # I/O parallelism per course (2-3 optimal for cloud storage)\n",
    "SEG_WORKERS = 1  # GPU-limited: always 1 for single GPU Colab\n",
    "FAST_MODE = False  # CPU-friendly mode (lower quality)\n",
    "\n",
    "# =======================================\n",
    "\n",
    "# Detect GPU\n",
    "import subprocess\n",
    "try:\n",
    "    subprocess.run(['nvidia-smi'], check=True, capture_output=True)\n",
    "    gpu_available = True\n",
    "    print(\"‚úÖ GPU detected\")\n",
    "except:\n",
    "    gpu_available = False\n",
    "    USE_GPU = False\n",
    "    SEG_WORKERS = 1\n",
    "    print(\"‚ö†Ô∏è No GPU detected - using CPU mode\")\n",
    "\n",
    "# Check DICOM directory\n",
    "if not os.path.exists(DICOM_ROOT):\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: DICOM directory not found: {DICOM_ROOT}\")\n",
    "    print(\"Please upload your DICOM files or update DICOM_ROOT variable above.\")\n",
    "else:\n",
    "    dicom_count = sum(1 for root, dirs, files in os.walk(DICOM_ROOT) for f in files if f.endswith('.dcm'))\n",
    "    print(f\"\\n‚úÖ DICOM directory found: {DICOM_ROOT}\")\n",
    "    print(f\"   Found {dicom_count} DICOM files\")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  GPU: {USE_GPU}\")\n",
    "print(f\"  Radiomics: {ENABLE_RADIOMICS}\")\n",
    "print(f\"  CT Cropping: {ENABLE_CT_CROPPING}\")\n",
    "print(f\"  Workers: {WORKERS} (I/O threads per course)\")\n",
    "print(f\"  Segmentation Workers: {SEG_WORKERS} (concurrent GPU tasks)\")\n",
    "print(f\"\\nüí° Tip: Cloud storage is I/O-bound. Lower worker counts (2-3)\")\n",
    "print(f\"   allow more courses in parallel, often improving total throughput.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### üß™ Radiomics Robustness Testing (Optional)\n",
    "\n",
    "**NEW**: Test feature stability under clinical variations!\n",
    "\n",
    "Radiomics robustness testing evaluates whether your radiomic features remain stable under:\n",
    "- **Volume changes** (¬±15-30%): Simulates segmentation uncertainty\n",
    "- **Translations** (¬±3-5mm): Simulates positioning variability\n",
    "- **Noise injection** (10-20 HU): Simulates scanner differences\n",
    "- **Contour randomization**: Simulates inter-observer variability\n",
    "\n",
    "**Outputs:**\n",
    "- ICC (Intraclass Correlation) ‚â•0.90 = robust features\n",
    "- CoV (Coefficient of Variation) ‚â§10% = stable features\n",
    "- Excel report with robust/acceptable/poor feature classifications\n",
    "\n",
    "‚è±Ô∏è **Time:** Adds 10-30 minutes per patient depending on intensity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# ============ ROBUSTNESS TESTING CONFIGURATION ============\n",
    "\n",
    "# Enable robustness testing?\n",
    "ENABLE_ROBUSTNESS = False  # Set to True to enable\n",
    "\n",
    "# Structures to test (use wildcards: \"GTV*\", \"CTV*\")\n",
    "ROBUSTNESS_STRUCTURES = [\n",
    "    \"GTV*\",\n",
    "    \"CTV*\", \n",
    "    \"PTV*\",\n",
    "    \"urinary_bladder\",\n",
    "    \"rectum\",\n",
    "    \"prostate\"\n",
    "]\n",
    "\n",
    "# Intensity level: \"mild\", \"standard\", \"aggressive\"\n",
    "# - mild: 10-15 perturbations per ROI (~5-10 min/patient with GPU)\n",
    "# - standard: 15-30 perturbations (~10-20 min/patient) [RECOMMENDED]\n",
    "# - aggressive: 30-60 perturbations (~30-60 min/patient, research-grade)\n",
    "ROBUSTNESS_INTENSITY = \"standard\"\n",
    "\n",
    "# Perturbation types (enable by setting values):\n",
    "ROBUSTNESS_VOLUME_CHANGES = [-0.15, 0.0, 0.15]  # ¬±15% volume changes\n",
    "ROBUSTNESS_TRANSLATIONS_MM = 0.0  # Set to 3.0 or 5.0 to enable translations\n",
    "ROBUSTNESS_NOISE_LEVELS = [0.0]  # Set to [0.0, 10.0, 20.0] to enable noise\n",
    "ROBUSTNESS_CONTOUR_REALIZATIONS = 0  # Set to 2-3 to enable contour randomization\n",
    "\n",
    "# Advanced: Large volume changes for organs (optional)\n",
    "ROBUSTNESS_LARGE_VOLUME_CHANGES = [-0.30, 0.0, 0.30]  # ¬±30% for OARs\n",
    "\n",
    "# ===========================================================\n",
    "\n",
    "print(\"Robustness Testing Configuration:\")\n",
    "print(f\"  Enabled: {ENABLE_ROBUSTNESS}\")\n",
    "if ENABLE_ROBUSTNESS:\n",
    "    print(f\"  Intensity: {ROBUSTNESS_INTENSITY}\")\n",
    "    print(f\"  Structures: {len(ROBUSTNESS_STRUCTURES)} patterns\")\n",
    "    print(f\"  Volume changes: {ROBUSTNESS_VOLUME_CHANGES}\")\n",
    "    print(f\"  Translations: {ROBUSTNESS_TRANSLATIONS_MM} mm\")\n",
    "    print(f\"  Noise levels: {ROBUSTNESS_NOISE_LEVELS} HU\")\n",
    "    print(f\"  Contour realizations: {ROBUSTNESS_CONTOUR_REALIZATIONS}\")\n",
    "else:\n",
    "    print(\"  (Set ENABLE_ROBUSTNESS = True to activate)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### üß™ Radiomics Robustness Testing (Optional)\n",
    "\n",
    "**NEW**: Test feature stability under clinical variations!\n",
    "\n",
    "Radiomics robustness testing evaluates whether your radiomic features remain stable under:\n",
    "- **Volume changes** (¬±15-30%): Simulates segmentation uncertainty\n",
    "- **Translations** (¬±3-5mm): Simulates positioning variability\n",
    "- **Noise injection** (10-20 HU): Simulates scanner differences\n",
    "- **Contour randomization**: Simulates inter-observer variability\n",
    "\n",
    "**Outputs:**\n",
    "- ICC (Intraclass Correlation) ‚â•0.90 = robust features\n",
    "- CoV (Coefficient of Variation) ‚â§10% = stable features\n",
    "- Excel report with robust/acceptable/poor feature classifications\n",
    "\n",
    "‚è±Ô∏è **Time:** Adds 10-30 minutes per patient depending on intensity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# ============ ROBUSTNESS TESTING CONFIGURATION ============\n",
    "\n",
    "# Enable robustness testing?\n",
    "ENABLE_ROBUSTNESS = False  # Set to True to enable\n",
    "\n",
    "# Structures to test (use wildcards: \"GTV*\", \"CTV*\")\n",
    "ROBUSTNESS_STRUCTURES = [\n",
    "    \"GTV*\",\n",
    "    \"CTV*\", \n",
    "    \"PTV*\",\n",
    "    \"urinary_bladder\",\n",
    "    \"rectum\",\n",
    "    \"prostate\"\n",
    "]\n",
    "\n",
    "# Intensity level: \"mild\", \"standard\", \"aggressive\"\n",
    "# - mild: 10-15 perturbations per ROI (~5-10 min/patient with GPU)\n",
    "# - standard: 15-30 perturbations (~10-20 min/patient) [RECOMMENDED]\n",
    "# - aggressive: 30-60 perturbations (~30-60 min/patient, research-grade)\n",
    "ROBUSTNESS_INTENSITY = \"standard\"\n",
    "\n",
    "# Perturbation types (enable by setting values):\n",
    "ROBUSTNESS_VOLUME_CHANGES = [-0.15, 0.0, 0.15]  # ¬±15% volume changes\n",
    "ROBUSTNESS_TRANSLATIONS_MM = 0.0  # Set to 3.0 or 5.0 to enable translations\n",
    "ROBUSTNESS_NOISE_LEVELS = [0.0]  # Set to [0.0, 10.0, 20.0] to enable noise\n",
    "ROBUSTNESS_CONTOUR_REALIZATIONS = 0  # Set to 2-3 to enable contour randomization\n",
    "\n",
    "# Advanced: Large volume changes for organs (optional)\n",
    "ROBUSTNESS_LARGE_VOLUME_CHANGES = [-0.30, 0.0, 0.30]  # ¬±30% for OARs\n",
    "\n",
    "# ===========================================================\n",
    "\n",
    "print(\"Robustness Testing Configuration:\")\n",
    "print(f\"  Enabled: {ENABLE_ROBUSTNESS}\")\n",
    "if ENABLE_ROBUSTNESS:\n",
    "    print(f\"  Intensity: {ROBUSTNESS_INTENSITY}\")\n",
    "    print(f\"  Structures: {len(ROBUSTNESS_STRUCTURES)} patterns\")\n",
    "    print(f\"  Volume changes: {ROBUSTNESS_VOLUME_CHANGES}\")\n",
    "    print(f\"  Translations: {ROBUSTNESS_TRANSLATIONS_MM} mm\")\n",
    "    print(f\"  Noise levels: {ROBUSTNESS_NOISE_LEVELS} HU\")\n",
    "    print(f\"  Contour realizations: {ROBUSTNESS_CONTOUR_REALIZATIONS}\")\n",
    "else:\n",
    "    print(\"  (Set ENABLE_ROBUSTNESS = True to activate)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generate_config"
   },
   "source": [
    "## 5Ô∏è‚É£ Generate Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "write_config"
   },
   "outputs": [],
   "source": [
    "config_yaml = f\"\"\"# RTpipeline Configuration for Google Colab\n",
    "# Generated automatically\n",
    "\n",
    "# Input/Output directories\n",
    "dicom_root: \"{DICOM_ROOT}\"\n",
    "output_dir: \"{OUTPUT_DIR}\"\n",
    "logs_dir: \"{LOGS_DIR}\"\n",
    "\n",
    "# Processing parameters\n",
    "workers: {WORKERS}\n",
    "\n",
    "segmentation:\n",
    "  workers: {SEG_WORKERS}\n",
    "  threads_per_worker: null\n",
    "  force: false\n",
    "  fast: {str(FAST_MODE).lower()}\n",
    "  roi_subset: null\n",
    "  extra_models: []\n",
    "  device: \"{'gpu' if USE_GPU else 'cpu'}\"\n",
    "  force_split: true\n",
    "  nr_threads_resample: 1\n",
    "  nr_threads_save: 1\n",
    "  num_proc_preprocessing: 1\n",
    "  num_proc_export: 1\n",
    "\n",
    "custom_models:\n",
    "  enabled: false\n",
    "  root: \"custom_models\"\n",
    "  models: []\n",
    "  workers: 1\n",
    "  force: false\n",
    "  nnunet_predict: \"nnUNet_predict\"\n",
    "  retain_weights: true\n",
    "  conda_activate: null\n",
    "\n",
    "radiomics:\n",
    "  sequential: false\n",
    "  params_file: \"/content/rtpipeline/rtpipeline/radiomics_params.yaml\"\n",
    "  mr_params_file: \"/content/rtpipeline/rtpipeline/radiomics_params_mr.yaml\"\n",
    "  thread_limit: 4\n",
    "  skip_rois:\n",
    "    - body\n",
    "    - couchsurface\n",
    "    - bones\n",
    "  max_voxels: 1500000000\n",
    "  min_voxels: 10\n",
    "\n",
    "aggregation:\n",
    "  threads: auto\n",
    "\n",
    "environments:\n",
    "  main: \"base\"\n",
    "  radiomics: \"base\"\n",
    "\n",
    "custom_structures: \"custom_structures_pelvic.yaml\"\n",
    "\n",
    "ct_cropping:\n",
    "  enabled: {str(ENABLE_CT_CROPPING).lower()}\n",
    "  region: \"{CROP_REGION}\"\n",
    "  superior_margin_cm: 2.0\n",
    "  inferior_margin_cm: 10.0\n",
    "  use_cropped_for_dvh: true\n",
    "  use_cropped_for_radiomics: true\n",
    "  keep_original: true\n",
    "\"\"\"\n",
    "\n",
    "# Write config file\n",
    "config_path = \"/content/config_colab.yaml\"\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_yaml)\n",
    "\n",
    "print(f\"‚úÖ Configuration written to: {config_path}\")\n",
    "print(\"\\nPreview:\")\n",
    "print(config_yaml[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run"
   },
   "source": [
    "## 6Ô∏è‚É£ Run Pipeline with Snakemake\n",
    "\n",
    "This uses Snakemake to orchestrate the pipeline with proper conda environment management:\n",
    "- **TotalSegmentator** runs in `rtpipeline` environment (numpy>=2.0)\n",
    "- **PyRadiomics** runs in `rtpipeline-radiomics` environment (numpy=1.26.x)\n",
    "\n",
    "‚è±Ô∏è **Estimated time:**\n",
    "- With GPU: 10-30 minutes per patient\n",
    "- Without GPU: 1-3 hours per patient\n",
    "\n",
    "**Note:** Colab may timeout after 12 hours. For large datasets, process in batches."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6Ô∏è‚É£b Run Radiomics Robustness Testing (Optional)\n",
    "\n",
    "Run this cell if you enabled robustness testing (`ENABLE_ROBUSTNESS = True`)\n",
    "\n",
    "This will:\n",
    "1. Apply perturbations to segmentations (volume, translation, noise, contour)\n",
    "2. Extract radiomic features for each perturbation\n",
    "3. Compute ICC and CoV stability metrics\n",
    "4. Generate Excel report with robust/acceptable/poor feature classifications"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "if ENABLE_ROBUSTNESS:\n",
    "    import subprocess\n",
    "    import os\n",
    "    import glob\n",
    "    \n",
    "    os.chdir('/content/rtpipeline')\n",
    "    \n",
    "    # Setup conda environment\n",
    "    os.environ['PATH'] = f\"/content/miniconda/bin:{os.environ.get('PATH', '')}\"\n",
    "    \n",
    "    print(\"=== Starting Radiomics Robustness Testing ===\")\n",
    "    print(f\"Configuration: /content/config_colab.yaml\")\n",
    "    print(f\"Structures: {ROBUSTNESS_STRUCTURES}\")\n",
    "    print(f\"Intensity: {ROBUSTNESS_INTENSITY}\")\n",
    "    print(\"Using conda environment: rtpipeline-radiomics (numpy=1.26.x)\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Find all course directories\n",
    "    course_dirs = glob.glob(f\"{OUTPUT_DIR}/Data_Snakemake/*/*\")\n",
    "    course_dirs = [d for d in course_dirs if os.path.isdir(d) and not d.endswith('_RESULTS') and not d.startswith('_')]\n",
    "    \n",
    "    if not course_dirs:\n",
    "        print(\"‚ö†Ô∏è No course directories found. Make sure the main pipeline completed successfully.\")\n",
    "    else:\n",
    "        print(f\"Found {len(course_dirs)} course(s) to process\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # Process each course\n",
    "        robustness_files = []\n",
    "        for i, course_dir in enumerate(course_dirs, 1):\n",
    "            course_name = os.path.basename(course_dir)\n",
    "            patient_name = os.path.basename(os.path.dirname(course_dir))\n",
    "            \n",
    "            print(f\"[{i}/{len(course_dirs)}] Processing: {patient_name}/{course_name}\")\n",
    "            \n",
    "            output_file = os.path.join(course_dir, \"radiomics_robustness_ct.parquet\")\n",
    "            \n",
    "            # Use conda run to execute in the radiomics environment\n",
    "            cmd = [\n",
    "                \"conda\", \"run\", \"-n\", \"rtpipeline-radiomics\",\n",
    "                \"python3\", \"-m\", \"rtpipeline.cli\",\n",
    "                \"radiomics-robustness\",\n",
    "                \"--course-dir\", course_dir,\n",
    "                \"--config\", \"/content/config_colab.yaml\",\n",
    "                \"--output\", output_file\n",
    "            ]\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "                print(f\"  ‚úÖ Complete: {output_file}\")\n",
    "                robustness_files.append(output_file)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"  ‚ö†Ô∏è Failed: {e}\")\n",
    "                print(f\"  Error: {e.stderr[:500]}\")\n",
    "            \n",
    "            print(\"\")\n",
    "        \n",
    "        # Aggregate results\n",
    "        if robustness_files:\n",
    "            print(\"=== Aggregating Robustness Results ===\")\n",
    "            \n",
    "            output_excel = f\"{OUTPUT_DIR}/_RESULTS/radiomics_robustness_summary.xlsx\"\n",
    "            \n",
    "            cmd = [\n",
    "                \"conda\", \"run\", \"-n\", \"rtpipeline-radiomics\",\n",
    "                \"python3\", \"-m\", \"rtpipeline.cli\",\n",
    "                \"radiomics-robustness-aggregate\",\n",
    "                \"--config\", \"/content/config_colab.yaml\",\n",
    "                \"--output\", output_excel,\n",
    "                \"--inputs\"\n",
    "            ] + robustness_files\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "                print(f\"‚úÖ Aggregated summary saved to: {output_excel}\")\n",
    "                print(\"\")\n",
    "                print(\"=== Robustness Testing Complete ===\")\n",
    "                print(f\"Results: {output_excel}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ö†Ô∏è Aggregation failed: {e}\")\n",
    "                print(f\"Error: {e.stderr[:500]}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No robustness results to aggregate\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Robustness testing disabled. Set ENABLE_ROBUSTNESS = True to enable.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_pipeline"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Export Python variables as environment variables for the shell\n",
    "os.environ['WORKERS'] = str(WORKERS)\n",
    "os.environ['OUTPUT_DIR'] = OUTPUT_DIR\n",
    "\n",
    "# Setup conda path\n",
    "os.environ['PATH'] = f\"/content/miniconda/bin:{os.environ.get('PATH', '')}\"\n",
    "\n",
    "# Change to rtpipeline directory\n",
    "os.chdir('/content/rtpipeline')\n",
    "\n",
    "print(\"=== Starting RTpipeline with Snakemake ===\")\n",
    "print(\"Configuration: /content/config_colab.yaml\")\n",
    "print(\"\")\n",
    "print(\"This will use separate conda environments:\")\n",
    "print(\"  - rtpipeline: for TotalSegmentator (numpy>=2.0)\")\n",
    "print(\"  - rtpipeline-radiomics: for PyRadiomics (numpy=1.26.x)\")\n",
    "print(\"\")\n",
    "\n",
    "# Install Snakemake if needed\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [\"conda\", \"run\", \"-n\", \"base\", \"snakemake\", \"--version\"],\n",
    "        check=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Installing Snakemake...\")\n",
    "    subprocess.run(\n",
    "        [\"conda\", \"install\", \"-n\", \"base\", \"-c\", \"conda-forge\", \"-c\", \"bioconda\", \"snakemake\", \"-y\", \"-q\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"‚úÖ Snakemake installed\")\n",
    "\n",
    "# Run Snakemake\n",
    "cmd = [\n",
    "    \"conda\", \"run\", \"-n\", \"base\", \"snakemake\",\n",
    "    \"--configfile\", \"/content/config_colab.yaml\",\n",
    "    \"--use-conda\",\n",
    "    \"--cores\", str(WORKERS),\n",
    "    \"--printshellcmds\",\n",
    "    \"--keep-going\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=False, text=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"=== Pipeline Complete ===\")\n",
    "print(f\"Results saved to: {OUTPUT_DIR}\")\n",
    "print(f\"Check aggregated results: {OUTPUT_DIR}/_RESULTS/\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## 7Ô∏è‚É£ View Results\n",
    "\n",
    "Load and preview the aggregated results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_results"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "results_dir = f\"{OUTPUT_DIR}/_RESULTS\"\n",
    "\n",
    "# Check if results exist\n",
    "if not os.path.exists(results_dir):\n",
    "    print(\"‚ö†Ô∏è Results directory not found. Pipeline may still be running or failed.\")\n",
    "    print(f\"Expected location: {results_dir}\")\n",
    "else:\n",
    "    print(\"‚úÖ Results found!\\n\")\n",
    "\n",
    "    # List result files\n",
    "    result_files = os.listdir(results_dir)\n",
    "    print(\"Available files:\")\n",
    "    for f in result_files:\n",
    "        if f.endswith('.xlsx'):\n",
    "            filepath = os.path.join(results_dir, f)\n",
    "            size_mb = os.path.getsize(filepath) / 1024 / 1024\n",
    "            print(f\"  - {f} ({size_mb:.2f} MB)\")\n",
    "\n",
    "    # Load DVH metrics\n",
    "    try:\n",
    "        dvh_path = os.path.join(results_dir, \"dvh_metrics.xlsx\")\n",
    "        dvh = pd.read_excel(dvh_path)\n",
    "        print(f\"\\n‚úÖ Loaded DVH metrics: {len(dvh)} rows\")\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        display(dvh.head())\n",
    "\n",
    "        print(\"\\nStructures found:\")\n",
    "        print(dvh['Structure'].value_counts().head(10))\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Could not load DVH metrics: {e}\")\n",
    "\n",
    "    # Load radiomics\n",
    "    if ENABLE_RADIOMICS:\n",
    "        try:\n",
    "            rad_path = os.path.join(results_dir, \"radiomics_ct.xlsx\")\n",
    "            radiomics = pd.read_excel(rad_path)\n",
    "            print(f\"\\n‚úÖ Loaded radiomics: {len(radiomics)} rows, {len(radiomics.columns)} features\")\n",
    "            print(\"\\nFirst few rows:\")\n",
    "            display(radiomics.head())\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Could not load radiomics: {e}\")\n",
    "\n",
    "    # Load robustness results\n",
    "    if ENABLE_ROBUSTNESS:\n",
    "        try:\n",
    "            rob_path = os.path.join(results_dir, \"radiomics_robustness_summary.xlsx\")\n",
    "            \n",
    "            # Load different sheets\n",
    "            robust_summary = pd.read_excel(rob_path, sheet_name='global_summary')\n",
    "            robust_features = pd.read_excel(rob_path, sheet_name='robust_features')\n",
    "            \n",
    "            print(f\"\\n‚úÖ Loaded robustness summary: {len(robust_summary)} features analyzed\")\n",
    "            print(f\"   Robust features (ICC ‚â•0.90, CoV ‚â§10%): {len(robust_features)}\")\n",
    "            \n",
    "            print(\"\\nRobustness Summary (Top 10 most robust features):\")\n",
    "            display(robust_summary.nlargest(10, 'icc')[['feature_name', 'icc', 'cov_pct', 'robustness_label']])\n",
    "            \n",
    "            print(\"\\nRobustness distribution:\")\n",
    "            print(robust_summary['robustness_label'].value_counts())\n",
    "            \n",
    "            # Store for visualization\n",
    "            globals()['robustness_summary'] = robust_summary\n",
    "            globals()['robust_features'] = robust_features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Could not load robustness results: {e}\")\n",
    "            print(\"   Make sure you ran the robustness testing cell (6Ô∏è‚É£b)\")\n",
    "\n",
    "    # Load metadata\n",
    "    try:\n",
    "        meta_path = os.path.join(results_dir, \"case_metadata.xlsx\")\n",
    "        metadata = pd.read_excel(meta_path)\n",
    "        print(f\"\\n‚úÖ Loaded metadata: {len(metadata)} courses\")\n",
    "        print(\"\\nSummary:\")\n",
    "        print(f\"  Patients: {metadata['PatientID'].nunique()}\")\n",
    "        print(f\"  Courses: {len(metadata)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Could not load metadata: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize"
   },
   "source": [
    "## 8Ô∏è‚É£ Quick Visualization\n",
    "\n",
    "Create some basic plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# DVH metrics visualization\n",
    "try:\n",
    "    # Plot mean dose by structure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Mean dose\n",
    "    top_structures = dvh.groupby('Structure')['Dmean_Gy'].mean().sort_values(ascending=False).head(10)\n",
    "    top_structures.plot(kind='barh', ax=axes[0], color='steelblue')\n",
    "    axes[0].set_xlabel('Mean Dose (Gy)')\n",
    "    axes[0].set_title('Top 10 Structures by Mean Dose')\n",
    "\n",
    "    # Volume distribution\n",
    "    dvh['ROI_Volume_cc'].hist(bins=50, ax=axes[1], color='coral', edgecolor='black')\n",
    "    axes[1].set_xlabel('ROI Volume (cc)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('ROI Volume Distribution')\n",
    "    axes[1].set_yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"‚úÖ Visualizations created\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not create visualizations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### üß™ Robustness Visualizations\n",
    "\n",
    "Visualize feature stability metrics (only if robustness testing was enabled)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "if ENABLE_ROBUSTNESS and 'robustness_summary' in globals():\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    try:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # 1. ICC Distribution\n",
    "        ax = axes[0, 0]\n",
    "        robustness_summary['icc'].hist(bins=50, ax=ax, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        ax.axvline(0.90, color='green', linestyle='--', linewidth=2, label='Robust threshold (‚â•0.90)')\n",
    "        ax.axvline(0.75, color='orange', linestyle='--', linewidth=2, label='Acceptable threshold (‚â•0.75)')\n",
    "        ax.set_xlabel('ICC (Intraclass Correlation Coefficient)', fontsize=12)\n",
    "        ax.set_ylabel('Number of Features', fontsize=12)\n",
    "        ax.set_title('ICC Distribution Across All Features', fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. CoV Distribution\n",
    "        ax = axes[0, 1]\n",
    "        # Filter out extreme values for better visualization\n",
    "        cov_filtered = robustness_summary[robustness_summary['cov_pct'] <= 100]['cov_pct']\n",
    "        cov_filtered.hist(bins=50, ax=ax, color='coral', edgecolor='black', alpha=0.7)\n",
    "        ax.axvline(10, color='green', linestyle='--', linewidth=2, label='Robust threshold (‚â§10%)')\n",
    "        ax.axvline(20, color='orange', linestyle='--', linewidth=2, label='Acceptable threshold (‚â§20%)')\n",
    "        ax.set_xlabel('CoV - Coefficient of Variation (%)', fontsize=12)\n",
    "        ax.set_ylabel('Number of Features', fontsize=12)\n",
    "        ax.set_title('CoV Distribution Across All Features', fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Robustness Category Distribution\n",
    "        ax = axes[1, 0]\n",
    "        category_counts = robustness_summary['robustness_label'].value_counts()\n",
    "        colors = {'robust': 'green', 'acceptable': 'orange', 'poor': 'red'}\n",
    "        category_colors = [colors.get(cat, 'gray') for cat in category_counts.index]\n",
    "        category_counts.plot(kind='bar', ax=ax, color=category_colors, edgecolor='black', alpha=0.7)\n",
    "        ax.set_xlabel('Robustness Category', fontsize=12)\n",
    "        ax.set_ylabel('Number of Features', fontsize=12)\n",
    "        ax.set_title('Feature Distribution by Robustness Category', fontsize=14, fontweight='bold')\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add percentage labels on bars\n",
    "        for i, (cat, count) in enumerate(category_counts.items()):\n",
    "            pct = 100 * count / len(robustness_summary)\n",
    "            ax.text(i, count + 1, f'{count}\\n({pct:.1f}%)', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # 4. ICC vs CoV Scatter Plot\n",
    "        ax = axes[1, 1]\n",
    "        \n",
    "        # Create color map for categories\n",
    "        color_map = {'robust': 'green', 'acceptable': 'orange', 'poor': 'red'}\n",
    "        colors_list = robustness_summary['robustness_label'].map(color_map)\n",
    "        \n",
    "        # Scatter plot (limit CoV to 100 for better visualization)\n",
    "        plot_data = robustness_summary[robustness_summary['cov_pct'] <= 100]\n",
    "        scatter = ax.scatter(plot_data['icc'], plot_data['cov_pct'], \n",
    "                           c=[color_map.get(x, 'gray') for x in plot_data['robustness_label']], \n",
    "                           alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Add threshold lines\n",
    "        ax.axvline(0.90, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label='ICC ‚â•0.90')\n",
    "        ax.axvline(0.75, color='orange', linestyle='--', linewidth=1.5, alpha=0.7, label='ICC ‚â•0.75')\n",
    "        ax.axhline(10, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label='CoV ‚â§10%')\n",
    "        ax.axhline(20, color='orange', linestyle='--', linewidth=1.5, alpha=0.7, label='CoV ‚â§20%')\n",
    "        \n",
    "        # Add shaded regions for robustness zones\n",
    "        ax.fill_between([0.90, 1.0], 0, 10, alpha=0.1, color='green', label='Robust zone')\n",
    "        ax.fill_between([0.75, 0.90], 0, 20, alpha=0.1, color='orange')\n",
    "        \n",
    "        ax.set_xlabel('ICC', fontsize=12)\n",
    "        ax.set_ylabel('CoV (%)', fontsize=12)\n",
    "        ax.set_title('ICC vs CoV: Feature Stability Landscape', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlim([0, 1.0])\n",
    "        ax.set_ylim([0, 100])\n",
    "        ax.legend(loc='upper right', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ROBUSTNESS SUMMARY STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nTotal features analyzed: {len(robustness_summary)}\")\n",
    "        print(f\"\\nICC Statistics:\")\n",
    "        print(f\"  Mean ICC: {robustness_summary['icc'].mean():.3f}\")\n",
    "        print(f\"  Median ICC: {robustness_summary['icc'].median():.3f}\")\n",
    "        print(f\"  Features with ICC ‚â•0.90: {(robustness_summary['icc'] >= 0.90).sum()} ({100*(robustness_summary['icc'] >= 0.90).sum()/len(robustness_summary):.1f}%)\")\n",
    "        print(f\"  Features with ICC ‚â•0.75: {(robustness_summary['icc'] >= 0.75).sum()} ({100*(robustness_summary['icc'] >= 0.75).sum()/len(robustness_summary):.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nCoV Statistics:\")\n",
    "        print(f\"  Mean CoV: {robustness_summary['cov_pct'].mean():.2f}%\")\n",
    "        print(f\"  Median CoV: {robustness_summary['cov_pct'].median():.2f}%\")\n",
    "        print(f\"  Features with CoV ‚â§10%: {(robustness_summary['cov_pct'] <= 10).sum()} ({100*(robustness_summary['cov_pct'] <= 10).sum()/len(robustness_summary):.1f}%)\")\n",
    "        print(f\"  Features with CoV ‚â§20%: {(robustness_summary['cov_pct'] <= 20).sum()} ({100*(robustness_summary['cov_pct'] <= 20).sum()/len(robustness_summary):.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nRobustness Categories:\")\n",
    "        for cat in ['robust', 'acceptable', 'poor']:\n",
    "            count = (robustness_summary['robustness_label'] == cat).sum()\n",
    "            pct = 100 * count / len(robustness_summary)\n",
    "            print(f\"  {cat.capitalize()}: {count} ({pct:.1f}%)\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\n‚úÖ Robustness visualizations created\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not create robustness visualizations: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "elif ENABLE_ROBUSTNESS:\n",
    "    print(\"‚ö†Ô∏è Robustness results not loaded. Make sure you ran the results viewing cell (7Ô∏è‚É£) first.\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Robustness testing was not enabled. Set ENABLE_ROBUSTNESS = True to generate robustness visualizations.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 9Ô∏è‚É£ Download Results\n",
    "\n",
    "Download results to your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip_results"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create ZIP archive of results\n",
    "echo \"Creating results archive...\"\n",
    "cd /content\n",
    "zip -r -q results.zip output/_RESULTS/\n",
    "\n",
    "echo \"‚úÖ Results archived: /content/results.zip\"\n",
    "ls -lh /content/results.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_zip"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading results.zip...\")\n",
    "files.download('/content/results.zip')\n",
    "print(\"\\n‚úÖ Download started. Check your browser's download folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_drive"
   },
   "source": [
    "### Alternative: Save to Google Drive\n",
    "\n",
    "If you mounted Google Drive earlier, copy results there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy_to_drive"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check if Drive is mounted\n",
    "if [ -d \"/content/drive/MyDrive\" ]; then\n",
    "    echo \"Copying results to Google Drive...\"\n",
    "    cp -r /content/output/_RESULTS /content/drive/MyDrive/rtpipeline_results_$(date +%Y%m%d_%H%M%S)\n",
    "    echo \"‚úÖ Results copied to: /content/drive/MyDrive/rtpipeline_results_*\"\n",
    "else\n",
    "    echo \"‚ö†Ô∏è Google Drive not mounted. Run the 'Mount Google Drive' cell first.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "## üßπ Cleanup (Optional)\n",
    "\n",
    "Free up space by removing large intermediate files:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "cleanup_files"
   },
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- **Output Format Guide:** [output_format.md](https://github.com/kstawiski/rtpipeline/blob/main/output_format.md)\n",
    "- **Quick Reference:** [output_format_quick_ref.md](https://github.com/kstawiski/rtpipeline/blob/main/output_format_quick_ref.md)\n",
    "- **Radiomics Robustness Guide:** [RADIOMICS_ROBUSTNESS.md](https://github.com/kstawiski/rtpipeline/blob/main/RADIOMICS_ROBUSTNESS.md)\n",
    "- **GitHub Repository:** https://github.com/kstawiski/rtpipeline\n",
    "- **Issues/Questions:** https://github.com/kstawiski/rtpipeline/issues\n",
    "\n",
    "## ‚ö†Ô∏è Troubleshooting\n",
    "\n",
    "**Pipeline fails with GPU errors:**\n",
    "- Set `USE_GPU = False` in configuration cell\n",
    "- Reduce `SEG_WORKERS` to 1\n",
    "\n",
    "**Out of memory errors:**\n",
    "- Reduce `WORKERS` and `SEG_WORKERS`\n",
    "- Enable `FAST_MODE = True`\n",
    "- Process patients in smaller batches\n",
    "- For robustness testing, use \"mild\" intensity or reduce structures\n",
    "\n",
    "**Colab timeout:**\n",
    "- Upgrade to Colab Pro for longer runtime\n",
    "- Process in batches\n",
    "- Save intermediate results to Google Drive\n",
    "- Run robustness testing separately after main pipeline\n",
    "\n",
    "**Missing DICOM files:**\n",
    "- Ensure DICOM directory is correct\n",
    "- Check file permissions\n",
    "- Verify .dcm file extensions\n",
    "\n",
    "**Robustness testing fails:**\n",
    "- Ensure main pipeline completed successfully first\n",
    "- Check that radiomics extraction was enabled (`ENABLE_RADIOMICS = True`)\n",
    "- Verify structures exist in segmentation outputs\n",
    "- Try reducing `ROBUSTNESS_INTENSITY` to \"mild\"\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Version:** 2.0 (with Radiomics Robustness Testing)  \n",
    "**Compatible with:** rtpipeline v2.0+ as of November 2025"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
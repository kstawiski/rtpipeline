{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RTpipeline - Part 1: GPU Segmentation\n",
        "\n",
        "**Radiotherapy DICOM Processing Pipeline - Colab Edition**\n",
        "\n",
        "This notebook runs GPU-intensive segmentation tasks:\n",
        "- DICOM organization and conversion\n",
        "- TotalSegmentator auto-segmentation\n",
        "- Custom nnUNet models (if configured)\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **GPU Runtime**: Go to `Runtime > Change runtime type > GPU (T4)`\n",
        "2. **Google Drive**: Your DICOM data should be in Google Drive\n",
        "3. **Time**: ~15-30 min setup, ~5-10 min per patient for segmentation\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check GPU and Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\nGoogle Drive mounted at /content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Paths\n",
        "\n",
        "Adjust these paths to match your Google Drive structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Path Configuration { display-mode: \"form\" }\n",
        "#@markdown ### Input/Output Directories (in Google Drive)\n",
        "\n",
        "DICOM_INPUT = \"/content/drive/MyDrive/RTpipeline/Input\"  #@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/RTpipeline/Output\"  #@param {type:\"string\"}\n",
        "LOGS_DIR = \"/content/drive/MyDrive/RTpipeline/Logs\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Anatomical Region for CT Cropping\n",
        "ANATOMICAL_REGION = \"pelvis\"  #@param [\"pelvis\", \"thorax\", \"abdomen\", \"head_neck\", \"brain\"]\n",
        "\n",
        "#@markdown ### Processing Options\n",
        "ENABLE_CT_CROPPING = True  #@param {type:\"boolean\"}\n",
        "FAST_SEGMENTATION = False  #@param {type:\"boolean\"}\n",
        "\n",
        "# Create directories\n",
        "import os\n",
        "for d in [DICOM_INPUT, OUTPUT_DIR, LOGS_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "    print(f\"Directory ready: {d}\")\n",
        "\n",
        "# Check for input data\n",
        "if os.path.exists(DICOM_INPUT):\n",
        "    contents = os.listdir(DICOM_INPUT)\n",
        "    print(f\"\\nInput directory contains {len(contents)} items\")\n",
        "    if contents:\n",
        "        print(\"First 10:\", contents[:10])\n",
        "else:\n",
        "    print(f\"\\nWARNING: Input directory does not exist: {DICOM_INPUT}\")\n",
        "    print(\"Please upload your DICOM data to this location in Google Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Conda and RTpipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Install Miniconda\n",
        "if [ ! -d \"/content/miniconda\" ]; then\n",
        "    echo \"Installing Miniconda...\"\n",
        "    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "    bash miniconda.sh -b -p /content/miniconda\n",
        "    rm miniconda.sh\n",
        "    echo \"Miniconda installed.\"\n",
        "else\n",
        "    echo \"Miniconda already installed.\"\n",
        "fi\n",
        "\n",
        "# Add to PATH\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Install mamba for faster environment creation\n",
        "if ! command -v mamba &> /dev/null; then\n",
        "    echo \"Installing mamba...\"\n",
        "    conda install -y -c conda-forge mamba\n",
        "fi\n",
        "\n",
        "echo \"Done. Conda version: $(conda --version)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add conda to Python path\n",
        "import os\n",
        "os.environ['PATH'] = '/content/miniconda/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Clone rtpipeline if not already present\n",
        "if [ ! -d \"/content/rtpipeline\" ]; then\n",
        "    echo \"Cloning rtpipeline...\"\n",
        "    git clone https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n",
        "else\n",
        "    echo \"Updating rtpipeline...\"\n",
        "    cd /content/rtpipeline && git pull\n",
        "fi\n",
        "\n",
        "echo \"RTpipeline ready at /content/rtpipeline\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Create rtpipeline environment (for segmentation)\n",
        "if ! conda env list | grep -q \"rtpipeline\"; then\n",
        "    echo \"Creating rtpipeline environment (this takes ~10-15 minutes)...\"\n",
        "    mamba env create -f /content/rtpipeline/envs/rtpipeline.yaml\n",
        "    echo \"Environment created.\"\n",
        "else\n",
        "    echo \"rtpipeline environment already exists.\"\n",
        "fi\n",
        "\n",
        "# Install rtpipeline package\n",
        "echo \"Installing rtpipeline package...\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "pip install -e /content/rtpipeline\n",
        "\n",
        "echo \"\\nInstallation complete!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Install dcm2niix\n",
        "if ! command -v dcm2niix &> /dev/null; then\n",
        "    echo \"Installing dcm2niix...\"\n",
        "    wget -q https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20230411/dcm2niix_lnx.zip\n",
        "    unzip -o dcm2niix_lnx.zip -d /content/miniconda/bin/\n",
        "    chmod +x /content/miniconda/bin/dcm2niix\n",
        "    rm dcm2niix_lnx.zip\n",
        "    echo \"dcm2niix installed.\"\n",
        "else\n",
        "    echo \"dcm2niix already installed.\"\n",
        "fi\n",
        "\n",
        "dcm2niix -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Configuration File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate config.yaml\n",
        "config_content = f'''# RTpipeline Colab Configuration\n",
        "# Generated automatically - edit as needed\n",
        "\n",
        "container_mode: false\n",
        "\n",
        "# Directories\n",
        "dicom_root: \"{DICOM_INPUT}\"\n",
        "output_dir: \"{OUTPUT_DIR}\"\n",
        "logs_dir: \"{LOGS_DIR}\"\n",
        "\n",
        "# Processing\n",
        "max_workers: 2  # Colab has limited resources\n",
        "\n",
        "# Segmentation (GPU)\n",
        "segmentation:\n",
        "  max_workers: 1  # Sequential for GPU stability\n",
        "  force: false\n",
        "  fast: {str(FAST_SEGMENTATION).lower()}\n",
        "  device: \"gpu\"\n",
        "  force_split: true\n",
        "  nr_threads_resample: 4\n",
        "  nr_threads_save: 4\n",
        "  num_proc_preprocessing: 1\n",
        "  num_proc_export: 1\n",
        "\n",
        "# Custom models (disabled by default in Colab)\n",
        "custom_models:\n",
        "  enabled: false\n",
        "  root: \"/content/rtpipeline/custom_models\"\n",
        "\n",
        "# Radiomics (will be run in Part 2)\n",
        "radiomics:\n",
        "  sequential: true\n",
        "  params_file: \"/content/rtpipeline/rtpipeline/radiomics_params.yaml\"\n",
        "  mr_params_file: \"/content/rtpipeline/rtpipeline/radiomics_params_mr.yaml\"\n",
        "  skip_rois:\n",
        "    - body\n",
        "    - couchsurface\n",
        "    - couchinterior\n",
        "  max_voxels: 500000000\n",
        "  min_voxels: 10\n",
        "\n",
        "# Robustness analysis (disabled for Colab)\n",
        "radiomics_robustness:\n",
        "  enabled: false\n",
        "\n",
        "# Environment names\n",
        "environments:\n",
        "  main: \"rtpipeline\"\n",
        "  radiomics: \"rtpipeline-radiomics\"\n",
        "\n",
        "# Custom structures (use pelvic by default)\n",
        "custom_structures: \"/content/rtpipeline/custom_structures_pelvic.yaml\"\n",
        "\n",
        "# CT Cropping\n",
        "ct_cropping:\n",
        "  enabled: {str(ENABLE_CT_CROPPING).lower()}\n",
        "  region: \"{ANATOMICAL_REGION}\"\n",
        "  superior_margin_cm: 2.0\n",
        "  inferior_margin_cm: 10.0\n",
        "  use_cropped_for_dvh: true\n",
        "  use_cropped_for_radiomics: true\n",
        "  keep_original: true\n",
        "'''\n",
        "\n",
        "config_path = '/content/rtpipeline/config.colab.yaml'\n",
        "with open(config_path, 'w') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(f\"Configuration saved to: {config_path}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(config_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run GPU Tasks (Segmentation)\n",
        "\n",
        "This will:\n",
        "1. Organize DICOM files\n",
        "2. Convert to NIfTI\n",
        "3. Run TotalSegmentator on GPU\n",
        "4. Create RTSTRUCT files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "# Run Snakemake up to segmentation (GPU tasks)\n",
        "echo \"Starting GPU pipeline (organize + segment)...\"\n",
        "echo \"This may take 5-10 minutes per patient.\"\n",
        "echo \"\"\n",
        "\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    --until all_segmented \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee /content/drive/MyDrive/RTpipeline/Logs/part1_gpu.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verify Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "\n",
        "if output_path.exists():\n",
        "    # Count processed patients\n",
        "    patients = [d for d in output_path.iterdir() if d.is_dir() and not d.name.startswith('_')]\n",
        "    print(f\"Processed patients: {len(patients)}\")\n",
        "    \n",
        "    # Check for segmentation outputs\n",
        "    seg_count = 0\n",
        "    for patient in patients:\n",
        "        for course in patient.iterdir():\n",
        "            if course.is_dir():\n",
        "                seg_dir = course / 'Segmentation_TotalSegmentator'\n",
        "                if seg_dir.exists():\n",
        "                    seg_count += 1\n",
        "    \n",
        "    print(f\"Courses with segmentation: {seg_count}\")\n",
        "    \n",
        "    # Sample structure\n",
        "    if patients:\n",
        "        print(f\"\\nSample patient structure ({patients[0].name}):\")\n",
        "        for item in sorted(patients[0].rglob('*'))[:20]:\n",
        "            rel = item.relative_to(patients[0])\n",
        "            prefix = '  ' * (len(rel.parts) - 1)\n",
        "            print(f\"{prefix}{item.name}\")\n",
        "else:\n",
        "    print(f\"Output directory not found: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps\n",
        "\n",
        "GPU tasks are complete! Now:\n",
        "\n",
        "1. **Save your work**: Your results are already in Google Drive\n",
        "2. **Run Part 2**: Open `rtpipeline_colab_part2_cpu.ipynb` to run:\n",
        "   - DVH calculation\n",
        "   - Radiomics extraction\n",
        "   - Quality control\n",
        "   - Results aggregation\n",
        "\n",
        "Part 2 can run on CPU, so you don't need a GPU runtime.\n",
        "\n",
        "---\n",
        "\n",
        "**Tip**: You can disconnect this runtime now to free up GPU resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary\n",
        "print(\"=\"*60)\n",
        "print(\"PART 1 COMPLETE - GPU Segmentation\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nInput:  {DICOM_INPUT}\")\n",
        "print(f\"Output: {OUTPUT_DIR}\")\n",
        "print(f\"Logs:   {LOGS_DIR}\")\n",
        "print(f\"\\nRegion: {ANATOMICAL_REGION}\")\n",
        "print(f\"CT Cropping: {ENABLE_CT_CROPPING}\")\n",
        "print(\"\\nNext: Run Part 2 notebook for DVH, radiomics, and aggregation.\")"
      ]
    }
  ]
}

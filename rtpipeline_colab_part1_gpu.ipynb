{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RTpipeline - Part 1: Setup & GPU Segmentation\n",
        "\n",
        "**Radiotherapy DICOM Processing Pipeline - Colab Edition**\n",
        "\n",
        "This notebook sets up the complete pipeline configuration and runs GPU-intensive tasks:\n",
        "- **Complete pipeline configuration** (shared with Part 2)\n",
        "- DICOM organization and conversion\n",
        "- TotalSegmentator auto-segmentation (GPU)\n",
        "- Custom nnUNet models (if configured)\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **GPU Runtime**: Go to `Runtime > Change runtime type > GPU (T4)`\n",
        "2. **Google Drive**: Your DICOM data should be uploaded to Google Drive\n",
        "3. **Time**: ~15-30 min setup, ~5-10 min per patient for segmentation\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check GPU and Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU detected! Segmentation will be very slow.\")\n",
        "    print(\"Go to Runtime > Change runtime type > GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\nGoogle Drive mounted at /content/drive/MyDrive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Pipeline Configuration\n",
        "\n",
        "**Configure all pipeline settings here.** This configuration will be saved and used by Part 2.\n",
        "\n",
        "### 2.1 Directory Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ### Directory Configuration { display-mode: \"form\" }\n",
        "#@markdown **Set your data directories in Google Drive:**\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Input Directory (where your DICOM files are)\n",
        "DICOM_INPUT = \"/content/drive/MyDrive/RTpipeline/Input\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown #### Output Directory (pipeline results will be saved here)\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/RTpipeline/Output\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown #### Logs Directory\n",
        "LOGS_DIR = \"/content/drive/MyDrive/RTpipeline/Logs\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Create directories\n",
        "for d in [DICOM_INPUT, OUTPUT_DIR, LOGS_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# Verify input directory has data\n",
        "input_path = Path(DICOM_INPUT)\n",
        "if input_path.exists():\n",
        "    contents = list(input_path.iterdir())\n",
        "    print(f\"Input directory: {DICOM_INPUT}\")\n",
        "    print(f\"  Contains {len(contents)} items\")\n",
        "    if contents:\n",
        "        print(f\"  First items: {[c.name for c in contents[:5]]}\")\n",
        "    else:\n",
        "        print(\"\\n⚠️  WARNING: Input directory is EMPTY!\")\n",
        "        print(\"   Please upload your DICOM data to this location.\")\n",
        "else:\n",
        "    print(f\"\\n❌ ERROR: Input directory does not exist: {DICOM_INPUT}\")\n",
        "\n",
        "print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
        "print(f\"Logs directory: {LOGS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Processing Options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ### Processing Configuration { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Anatomical Region\n",
        "#@markdown Select the body region being analyzed (affects CT cropping landmarks):\n",
        "ANATOMICAL_REGION = \"pelvis\"  #@param [\"pelvis\", \"thorax\", \"abdomen\", \"head_neck\", \"brain\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### CT Cropping\n",
        "#@markdown Crop CTs to consistent anatomical boundaries for meaningful cross-patient DVH comparison:\n",
        "ENABLE_CT_CROPPING = True  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Superior margin above landmark (cm):\n",
        "SUPERIOR_MARGIN_CM = 2.0  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Inferior margin below landmark (cm):\n",
        "INFERIOR_MARGIN_CM = 10.0  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Segmentation Options\n",
        "#@markdown Fast mode (lower quality but faster):\n",
        "FAST_SEGMENTATION = False  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Radiomics Options\n",
        "#@markdown Enable radiomics robustness analysis (perturbation-based stability):\n",
        "ENABLE_ROBUSTNESS = False  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ROIs to skip in radiomics (comma-separated):\n",
        "SKIP_ROIS = \"body,couchsurface,couchinterior,couchexterior,bones\"  #@param {type:\"string\"}\n",
        "\n",
        "print(\"Configuration Summary:\")\n",
        "print(f\"  Region: {ANATOMICAL_REGION}\")\n",
        "print(f\"  CT Cropping: {ENABLE_CT_CROPPING}\")\n",
        "if ENABLE_CT_CROPPING:\n",
        "    print(f\"    Superior margin: {SUPERIOR_MARGIN_CM} cm\")\n",
        "    print(f\"    Inferior margin: {INFERIOR_MARGIN_CM} cm\")\n",
        "print(f\"  Fast segmentation: {FAST_SEGMENTATION}\")\n",
        "print(f\"  Radiomics robustness: {ENABLE_ROBUSTNESS}\")\n",
        "print(f\"  Skip ROIs: {SKIP_ROIS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Advanced Options (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ### Advanced Configuration { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Custom Structures\n",
        "#@markdown Enable custom structure definitions (boolean combinations, margins):\n",
        "ENABLE_CUSTOM_STRUCTURES = True  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Custom structures preset:\n",
        "CUSTOM_STRUCTURES_PRESET = \"pelvic\"  #@param [\"pelvic\", \"thorax\", \"head_neck\", \"none\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Performance Tuning\n",
        "#@markdown Max parallel workers (2 recommended for Colab):\n",
        "MAX_WORKERS = 2  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Robustness Analysis Settings (if enabled)\n",
        "#@markdown Structures to analyze (comma-separated, supports wildcards):\n",
        "ROBUSTNESS_STRUCTURES = \"GTV*,CTV*,PTV*,urinary_bladder,rectum,prostate\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Perturbation intensity:\n",
        "ROBUSTNESS_INTENSITY = \"standard\"  #@param [\"mild\", \"standard\", \"aggressive\"]\n",
        "\n",
        "print(\"Advanced Configuration:\")\n",
        "print(f\"  Custom structures: {ENABLE_CUSTOM_STRUCTURES} ({CUSTOM_STRUCTURES_PRESET})\")\n",
        "print(f\"  Max workers: {MAX_WORKERS}\")\n",
        "if ENABLE_ROBUSTNESS:\n",
        "    print(f\"  Robustness structures: {ROBUSTNESS_STRUCTURES}\")\n",
        "    print(f\"  Robustness intensity: {ROBUSTNESS_INTENSITY}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Install RTpipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Install Miniconda\n",
        "if [ ! -d \"/content/miniconda\" ]; then\n",
        "    echo \"Installing Miniconda...\"\n",
        "    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "    bash miniconda.sh -b -p /content/miniconda\n",
        "    rm miniconda.sh\n",
        "    echo \"Miniconda installed.\"\n",
        "else\n",
        "    echo \"Miniconda already installed.\"\n",
        "fi\n",
        "\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Install mamba for faster environment creation\n",
        "if ! command -v mamba &> /dev/null; then\n",
        "    echo \"Installing mamba...\"\n",
        "    conda install -y -c conda-forge mamba\n",
        "fi\n",
        "\n",
        "echo \"Done. Conda version: $(conda --version)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add conda to Python path\n",
        "import os\n",
        "os.environ['PATH'] = '/content/miniconda/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Clone rtpipeline\n",
        "if [ ! -d \"/content/rtpipeline\" ]; then\n",
        "    echo \"Cloning rtpipeline...\"\n",
        "    git clone https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n",
        "else\n",
        "    echo \"Updating rtpipeline...\"\n",
        "    cd /content/rtpipeline && git pull\n",
        "fi\n",
        "\n",
        "echo \"RTpipeline ready.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Create rtpipeline environment (for segmentation)\n",
        "if ! conda env list | grep -q \"^rtpipeline \"; then\n",
        "    echo \"Creating rtpipeline environment (this takes ~10-15 minutes)...\"\n",
        "    mamba env create -f /content/rtpipeline/envs/rtpipeline.yaml\n",
        "    echo \"Environment created.\"\n",
        "else\n",
        "    echo \"rtpipeline environment already exists.\"\n",
        "fi\n",
        "\n",
        "# Install rtpipeline package\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "pip install -e /content/rtpipeline 2>/dev/null\n",
        "\n",
        "echo \"\\nInstallation complete!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Install dcm2niix\n",
        "if ! command -v dcm2niix &> /dev/null; then\n",
        "    echo \"Installing dcm2niix...\"\n",
        "    wget -q https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20230411/dcm2niix_lnx.zip\n",
        "    unzip -o dcm2niix_lnx.zip -d /content/miniconda/bin/\n",
        "    chmod +x /content/miniconda/bin/dcm2niix\n",
        "    rm dcm2niix_lnx.zip\n",
        "    echo \"dcm2niix installed.\"\n",
        "else\n",
        "    echo \"dcm2niix already installed.\"\n",
        "fi\n",
        "\n",
        "dcm2niix -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Generate and Save Configuration\n",
        "\n",
        "This creates the configuration file that will be used by both Part 1 and Part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "# Parse skip ROIs\n",
        "skip_rois_list = [r.strip() for r in SKIP_ROIS.split(',') if r.strip()]\n",
        "\n",
        "# Parse robustness structures\n",
        "robustness_structures_list = [r.strip() for r in ROBUSTNESS_STRUCTURES.split(',') if r.strip()]\n",
        "\n",
        "# Determine custom structures file\n",
        "if ENABLE_CUSTOM_STRUCTURES and CUSTOM_STRUCTURES_PRESET != \"none\":\n",
        "    custom_structures_file = f\"/content/rtpipeline/custom_structures_{CUSTOM_STRUCTURES_PRESET}.yaml\"\n",
        "else:\n",
        "    custom_structures_file = None\n",
        "\n",
        "# Build configuration dictionary\n",
        "config = {\n",
        "    'container_mode': False,\n",
        "    \n",
        "    # Directories\n",
        "    'dicom_root': DICOM_INPUT,\n",
        "    'output_dir': OUTPUT_DIR,\n",
        "    'logs_dir': LOGS_DIR,\n",
        "    \n",
        "    # Processing\n",
        "    'max_workers': MAX_WORKERS,\n",
        "    \n",
        "    # Segmentation\n",
        "    'segmentation': {\n",
        "        'max_workers': 1,  # Sequential for GPU stability\n",
        "        'force': False,\n",
        "        'fast': FAST_SEGMENTATION,\n",
        "        'device': 'gpu',\n",
        "        'force_split': True,\n",
        "        'nr_threads_resample': 4,\n",
        "        'nr_threads_save': 4,\n",
        "        'num_proc_preprocessing': 1,\n",
        "        'num_proc_export': 1,\n",
        "    },\n",
        "    \n",
        "    # Custom models (disabled for Colab)\n",
        "    'custom_models': {\n",
        "        'enabled': False,\n",
        "        'root': '/content/rtpipeline/custom_models',\n",
        "    },\n",
        "    \n",
        "    # Radiomics\n",
        "    'radiomics': {\n",
        "        'sequential': True,\n",
        "        'params_file': '/content/rtpipeline/rtpipeline/radiomics_params.yaml',\n",
        "        'mr_params_file': '/content/rtpipeline/rtpipeline/radiomics_params_mr.yaml',\n",
        "        'skip_rois': skip_rois_list,\n",
        "        'max_voxels': 500000000,\n",
        "        'min_voxels': 10,\n",
        "    },\n",
        "    \n",
        "    # Radiomics robustness\n",
        "    'radiomics_robustness': {\n",
        "        'enabled': ENABLE_ROBUSTNESS,\n",
        "        'modes': ['segmentation_perturbation'],\n",
        "        'segmentation_perturbation': {\n",
        "            'apply_to_structures': robustness_structures_list,\n",
        "            'small_volume_changes': [-0.15, 0.0, 0.15],\n",
        "            'large_volume_changes': [-0.30, 0.0, 0.30],\n",
        "            'max_translation_mm': 0.0,\n",
        "            'n_random_contour_realizations': 0,\n",
        "            'noise_levels': [0.0],\n",
        "            'intensity': ROBUSTNESS_INTENSITY,\n",
        "        },\n",
        "        'metrics': {\n",
        "            'icc': {'implementation': 'pingouin', 'icc_type': 'ICC3', 'ci': True},\n",
        "            'cov': {'enabled': True},\n",
        "            'qcd': {'enabled': True},\n",
        "        },\n",
        "        'thresholds': {\n",
        "            'icc': {'robust': 0.90, 'acceptable': 0.75},\n",
        "            'cov': {'robust_pct': 10.0, 'acceptable_pct': 20.0},\n",
        "        },\n",
        "    },\n",
        "    \n",
        "    # Environments\n",
        "    'environments': {\n",
        "        'main': 'rtpipeline',\n",
        "        'radiomics': 'rtpipeline-radiomics',\n",
        "    },\n",
        "    \n",
        "    # Custom structures\n",
        "    'custom_structures': custom_structures_file,\n",
        "    \n",
        "    # CT Cropping\n",
        "    'ct_cropping': {\n",
        "        'enabled': ENABLE_CT_CROPPING,\n",
        "        'region': ANATOMICAL_REGION,\n",
        "        'superior_margin_cm': SUPERIOR_MARGIN_CM,\n",
        "        'inferior_margin_cm': INFERIOR_MARGIN_CM,\n",
        "        'use_cropped_for_dvh': True,\n",
        "        'use_cropped_for_radiomics': True,\n",
        "        'keep_original': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Save configuration to Google Drive (for Part 2 to use)\n",
        "config_dir = os.path.dirname(OUTPUT_DIR)\n",
        "config_path_gdrive = os.path.join(config_dir, 'rtpipeline_config.yaml')\n",
        "config_path_local = '/content/rtpipeline/config.colab.yaml'\n",
        "\n",
        "# Save to both locations\n",
        "for path in [config_path_gdrive, config_path_local]:\n",
        "    with open(path, 'w') as f:\n",
        "        yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(\"Configuration saved to:\")\n",
        "print(f\"  - {config_path_gdrive} (persistent, for Part 2)\")\n",
        "print(f\"  - {config_path_local} (local, for this session)\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONFIGURATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Input:  {DICOM_INPUT}\")\n",
        "print(f\"Output: {OUTPUT_DIR}\")\n",
        "print(f\"Region: {ANATOMICAL_REGION}\")\n",
        "print(f\"CT Cropping: {ENABLE_CT_CROPPING}\")\n",
        "print(f\"Robustness: {ENABLE_ROBUSTNESS}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Run GPU Tasks (Segmentation)\n",
        "\n",
        "This will:\n",
        "1. Organize DICOM files by patient/course\n",
        "2. Convert CT to NIfTI format\n",
        "3. Run TotalSegmentator on GPU\n",
        "4. Generate RTSTRUCT files with auto-segmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"================================================\"\n",
        "echo \"Starting GPU Pipeline (Organize + Segment)\"\n",
        "echo \"================================================\"\n",
        "echo \"This may take 5-10 minutes per patient.\"\n",
        "echo \"\"\n",
        "\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    --until all_segmented \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee -a \"$(cat config.colab.yaml | grep logs_dir | cut -d':' -f2 | tr -d ' ')/part1_gpu.log\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Verify Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PART 1 RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if output_path.exists():\n",
        "    # Count patients and courses\n",
        "    patients = [d for d in output_path.iterdir() if d.is_dir() and not d.name.startswith('_')]\n",
        "    \n",
        "    seg_count = 0\n",
        "    course_count = 0\n",
        "    for patient in patients:\n",
        "        for course in patient.iterdir():\n",
        "            if course.is_dir():\n",
        "                course_count += 1\n",
        "                seg_dir = course / 'Segmentation_TotalSegmentator'\n",
        "                if seg_dir.exists() and list(seg_dir.glob('*.nii.gz')):\n",
        "                    seg_count += 1\n",
        "    \n",
        "    print(f\"\\nPatients found: {len(patients)}\")\n",
        "    print(f\"Treatment courses: {course_count}\")\n",
        "    print(f\"Courses with segmentation: {seg_count}\")\n",
        "    \n",
        "    if seg_count > 0:\n",
        "        print(\"\\n✅ Segmentation completed successfully!\")\n",
        "        print(\"\\nYou can now proceed to Part 2 for analysis.\")\n",
        "    else:\n",
        "        print(\"\\n⚠️  No segmentations found. Check the logs for errors.\")\n",
        "    \n",
        "    # Show sample structure\n",
        "    if patients:\n",
        "        print(f\"\\n--- Sample patient structure ({patients[0].name}) ---\")\n",
        "        for item in sorted(list(patients[0].rglob('*'))[:15]):\n",
        "            rel = item.relative_to(patients[0])\n",
        "            prefix = '  ' * (len(rel.parts) - 1)\n",
        "            print(f\"{prefix}{item.name}\")\n",
        "else:\n",
        "    print(f\"\\n❌ Output directory not found: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Next Steps\n",
        "\n",
        "GPU tasks (segmentation) are complete!\n",
        "\n",
        "### Continue with Part 2:\n",
        "\n",
        "1. **Open** `rtpipeline_colab_part2_cpu.ipynb`\n",
        "2. **Run Part 2** to perform:\n",
        "   - DVH calculation\n",
        "   - Radiomics extraction\n",
        "   - Quality control\n",
        "   - Results aggregation\n",
        "\n",
        "Part 2 will automatically load your configuration from Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "**Tip**: You can disconnect this runtime now to free up GPU resources. Part 2 only needs CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\"*60)\n",
        "print(\"PART 1 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nConfiguration saved at:\")\n",
        "print(f\"  {config_path_gdrive}\")\n",
        "print(f\"\\nPart 2 will automatically load this configuration.\")\n",
        "print(f\"\\nOutput location: {OUTPUT_DIR}\")\n",
        "print(f\"Logs location: {LOGS_DIR}\")"
      ]
    }
  ]
}

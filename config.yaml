# Snakemake configuration for rtpipeline

# Input/Output directories
dicom_root: "Example_data"
output_dir: "Data_Snakemake"
logs_dir: "Logs_Snakemake"

# Processing parameters
workers: 2
segmentation:
  workers: 2  # TotalSegmentator concurrency (set per-course parallelism)
  threads_per_worker: null  # CPU threads allowed per TotalSegmentator invocation (null => no limit)
  force: false  # Set true to re-run segmentation even when outputs exist
  fast: false
  roi_subset: null
  extra_models: []   # Optional list of additional TotalSegmentator tasks, e.g. ["lung_vessels"]

custom_models:
  enabled: true
  root: "custom_models"
  models: []           # Optional allowlist of model names; leave empty to run all
  workers: 1           # Concurrent courses for custom models (GPU intensive; default 1)
  force: false         # Force re-run even if outputs already exist
  nnunet_predict: "nnUNetv2_predict"
  retain_weights: true # Keep extracted nnUNet caches between runs (set false to purge after each run)
  conda_activate: null  # Override conda activation for custom models (default: segmentation setting)

radiomics:
  sequential: false
  params_file: "rtpipeline/radiomics_params.yaml"
  mr_params_file: "rtpipeline/radiomics_params_mr.yaml"
  thread_limit: 4  # CPU threads per radiomics worker (null => no limit)
  skip_rois:
    - body
    - couchsurface
    - couchinterior
    - couchexterior
    - bones
    - m1
    - m2
  max_voxels: 1500000000  # 1.5 billion voxels max (approx 1500x1000x1000)
  min_voxels: 10

aggregation:
  threads: null

# Environment names
environments:
  main: "rtpipeline"          # NumPy 2.x for TotalSegmentator
  radiomics: "rtpipeline-radiomics"  # NumPy 1.x for PyRadiomics

# Custom structures configuration
custom_structures: "custom_structures_pelvic.yaml"

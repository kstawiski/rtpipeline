{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RTpipeline - Part 2: CPU Analysis\n",
        "\n",
        "**Radiotherapy DICOM Processing Pipeline - Colab Edition**\n",
        "\n",
        "This notebook runs CPU-intensive analysis tasks:\n",
        "- DVH (Dose-Volume Histogram) calculation\n",
        "- Radiomics feature extraction\n",
        "- Quality control reports\n",
        "- Results aggregation\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **Part 1 Complete**: Run `rtpipeline_colab_part1_gpu.ipynb` first for segmentation\n",
        "2. **Runtime**: CPU runtime is sufficient (no GPU needed)\n",
        "3. **Time**: ~2-5 min per patient for full analysis\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Google Drive mounted at /content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Paths\n",
        "\n",
        "**Important**: Use the same paths as Part 1!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Path Configuration { display-mode: \"form\" }\n",
        "#@markdown ### Directories (must match Part 1)\n",
        "\n",
        "DICOM_INPUT = \"/content/drive/MyDrive/RTpipeline/Input\"  #@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/RTpipeline/Output\"  #@param {type:\"string\"}\n",
        "LOGS_DIR = \"/content/drive/MyDrive/RTpipeline/Logs\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Anatomical Region (must match Part 1)\n",
        "ANATOMICAL_REGION = \"pelvis\"  #@param [\"pelvis\", \"thorax\", \"abdomen\", \"head_neck\", \"brain\"]\n",
        "\n",
        "#@markdown ### Processing Options\n",
        "ENABLE_CT_CROPPING = True  #@param {type:\"boolean\"}\n",
        "ENABLE_ROBUSTNESS = False  #@param {type:\"boolean\"}\n",
        "\n",
        "# Verify Part 1 outputs exist\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "if output_path.exists():\n",
        "    patients = [d for d in output_path.iterdir() if d.is_dir() and not d.name.startswith('_')]\n",
        "    seg_count = sum(1 for p in patients for c in p.iterdir() \n",
        "                    if c.is_dir() and (c / 'Segmentation_TotalSegmentator').exists())\n",
        "    print(f\"Found {len(patients)} patients with {seg_count} segmented courses\")\n",
        "    \n",
        "    if seg_count == 0:\n",
        "        print(\"\\nWARNING: No segmentations found!\")\n",
        "        print(\"Please run Part 1 (GPU notebook) first.\")\n",
        "else:\n",
        "    print(f\"ERROR: Output directory not found: {OUTPUT_DIR}\")\n",
        "    print(\"Please run Part 1 first or check your path configuration.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Install Miniconda\n",
        "if [ ! -d \"/content/miniconda\" ]; then\n",
        "    echo \"Installing Miniconda...\"\n",
        "    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "    bash miniconda.sh -b -p /content/miniconda\n",
        "    rm miniconda.sh\n",
        "    echo \"Miniconda installed.\"\n",
        "else\n",
        "    echo \"Miniconda already installed.\"\n",
        "fi\n",
        "\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Install mamba\n",
        "if ! command -v mamba &> /dev/null; then\n",
        "    echo \"Installing mamba...\"\n",
        "    conda install -y -c conda-forge mamba\n",
        "fi\n",
        "\n",
        "echo \"Done.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PATH'] = '/content/miniconda/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Clone/update rtpipeline\n",
        "if [ ! -d \"/content/rtpipeline\" ]; then\n",
        "    echo \"Cloning rtpipeline...\"\n",
        "    git clone https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n",
        "else\n",
        "    echo \"Updating rtpipeline...\"\n",
        "    cd /content/rtpipeline && git pull\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Create rtpipeline-radiomics environment (PyRadiomics requires NumPy 1.x)\n",
        "if ! conda env list | grep -q \"rtpipeline-radiomics\"; then\n",
        "    echo \"Creating rtpipeline-radiomics environment (this takes ~10 minutes)...\"\n",
        "    mamba env create -f /content/rtpipeline/envs/rtpipeline-radiomics.yaml\n",
        "    echo \"Environment created.\"\n",
        "else\n",
        "    echo \"rtpipeline-radiomics environment already exists.\"\n",
        "fi\n",
        "\n",
        "# Also ensure main environment exists for DVH\n",
        "if ! conda env list | grep -q \"^rtpipeline \"; then\n",
        "    echo \"Creating rtpipeline environment...\"\n",
        "    mamba env create -f /content/rtpipeline/envs/rtpipeline.yaml\n",
        "fi\n",
        "\n",
        "# Install rtpipeline package in both environments\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "\n",
        "conda activate rtpipeline\n",
        "pip install -e /content/rtpipeline 2>/dev/null || true\n",
        "\n",
        "conda activate rtpipeline-radiomics\n",
        "pip install -e /content/rtpipeline 2>/dev/null || true\n",
        "\n",
        "echo \"\\nEnvironments ready!\"\n",
        "conda env list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate config.yaml (same as Part 1 but may have robustness enabled)\n",
        "config_content = f'''# RTpipeline Colab Configuration - Part 2\n",
        "# Generated automatically\n",
        "\n",
        "container_mode: false\n",
        "\n",
        "# Directories\n",
        "dicom_root: \"{DICOM_INPUT}\"\n",
        "output_dir: \"{OUTPUT_DIR}\"\n",
        "logs_dir: \"{LOGS_DIR}\"\n",
        "\n",
        "# Processing\n",
        "max_workers: 2\n",
        "\n",
        "# Segmentation (already done in Part 1)\n",
        "segmentation:\n",
        "  max_workers: 1\n",
        "  force: false\n",
        "  fast: false\n",
        "  device: \"cpu\"  # Not needed for Part 2\n",
        "\n",
        "# Custom models\n",
        "custom_models:\n",
        "  enabled: false\n",
        "  root: \"/content/rtpipeline/custom_models\"\n",
        "\n",
        "# Radiomics\n",
        "radiomics:\n",
        "  sequential: true  # More stable in Colab\n",
        "  params_file: \"/content/rtpipeline/rtpipeline/radiomics_params.yaml\"\n",
        "  mr_params_file: \"/content/rtpipeline/rtpipeline/radiomics_params_mr.yaml\"\n",
        "  skip_rois:\n",
        "    - body\n",
        "    - couchsurface\n",
        "    - couchinterior\n",
        "    - couchexterior\n",
        "    - bones\n",
        "  max_voxels: 500000000\n",
        "  min_voxels: 10\n",
        "\n",
        "# Robustness analysis\n",
        "radiomics_robustness:\n",
        "  enabled: {str(ENABLE_ROBUSTNESS).lower()}\n",
        "  modes:\n",
        "    - segmentation_perturbation\n",
        "  segmentation_perturbation:\n",
        "    apply_to_structures:\n",
        "      - \"GTV*\"\n",
        "      - \"CTV*\"\n",
        "      - \"PTV*\"\n",
        "    small_volume_changes: [-0.15, 0.0, 0.15]\n",
        "    large_volume_changes: [-0.30, 0.0, 0.30]\n",
        "    intensity: \"standard\"\n",
        "\n",
        "# Environment names\n",
        "environments:\n",
        "  main: \"rtpipeline\"\n",
        "  radiomics: \"rtpipeline-radiomics\"\n",
        "\n",
        "# Custom structures\n",
        "custom_structures: \"/content/rtpipeline/custom_structures_pelvic.yaml\"\n",
        "\n",
        "# CT Cropping\n",
        "ct_cropping:\n",
        "  enabled: {str(ENABLE_CT_CROPPING).lower()}\n",
        "  region: \"{ANATOMICAL_REGION}\"\n",
        "  superior_margin_cm: 2.0\n",
        "  inferior_margin_cm: 10.0\n",
        "  use_cropped_for_dvh: true\n",
        "  use_cropped_for_radiomics: true\n",
        "  keep_original: true\n",
        "'''\n",
        "\n",
        "config_path = '/content/rtpipeline/config.colab.yaml'\n",
        "with open(config_path, 'w') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(f\"Configuration saved to: {config_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run DVH Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"Running DVH calculation...\"\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    --until all_dvh \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee /content/drive/MyDrive/RTpipeline/Logs/part2_dvh.log\n",
        "\n",
        "echo \"\\nDVH calculation complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Radiomics Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline-radiomics\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"Running radiomics extraction...\"\n",
        "echo \"(This may take several minutes per patient)\"\n",
        "\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    --until all_radiomics \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee /content/drive/MyDrive/RTpipeline/Logs/part2_radiomics.log\n",
        "\n",
        "echo \"\\nRadiomics extraction complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Quality Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"Running quality control...\"\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    --until all_qc \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee /content/drive/MyDrive/RTpipeline/Logs/part2_qc.log\n",
        "\n",
        "echo \"\\nQuality control complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Aggregate Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"Aggregating all results...\"\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    all \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee /content/drive/MyDrive/RTpipeline/Logs/part2_aggregate.log\n",
        "\n",
        "echo \"\\nAggregation complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(OUTPUT_DIR) / '_RESULTS'\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PIPELINE RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if results_dir.exists():\n",
        "    print(f\"\\nResults directory: {results_dir}\")\n",
        "    print(\"\\nAvailable files:\")\n",
        "    for f in sorted(results_dir.glob('*.xlsx')):\n",
        "        size_mb = f.stat().st_size / 1e6\n",
        "        print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
        "else:\n",
        "    print(f\"Results directory not found: {results_dir}\")\n",
        "    print(\"The pipeline may not have completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preview DVH metrics\n",
        "dvh_file = Path(OUTPUT_DIR) / '_RESULTS' / 'dvh_metrics.xlsx'\n",
        "\n",
        "if dvh_file.exists():\n",
        "    dvh = pd.read_excel(dvh_file)\n",
        "    print(f\"DVH Metrics: {len(dvh)} rows\")\n",
        "    print(f\"Columns: {list(dvh.columns)[:10]}...\")\n",
        "    print(f\"\\nStructures: {dvh['Structure'].nunique()}\")\n",
        "    print(f\"Patients: {dvh['PatientID'].nunique()}\")\n",
        "    display(dvh.head(10))\n",
        "else:\n",
        "    print(\"DVH metrics file not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preview radiomics features\n",
        "radiomics_file = Path(OUTPUT_DIR) / '_RESULTS' / 'radiomics_ct.xlsx'\n",
        "\n",
        "if radiomics_file.exists():\n",
        "    rad = pd.read_excel(radiomics_file)\n",
        "    print(f\"Radiomics: {len(rad)} rows, {len(rad.columns)} features\")\n",
        "    print(f\"\\nStructures: {rad['Structure'].nunique() if 'Structure' in rad.columns else 'N/A'}\")\n",
        "    \n",
        "    # Count feature types\n",
        "    original = len([c for c in rad.columns if c.startswith('original_')])\n",
        "    wavelet = len([c for c in rad.columns if c.startswith('wavelet')])\n",
        "    log = len([c for c in rad.columns if c.startswith('log-sigma')])\n",
        "    print(f\"\\nFeature breakdown:\")\n",
        "    print(f\"  Original: {original}\")\n",
        "    print(f\"  Wavelet: {wavelet}\")\n",
        "    print(f\"  LoG: {log}\")\n",
        "else:\n",
        "    print(\"Radiomics file not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check QC summary\n",
        "qc_file = Path(OUTPUT_DIR) / '_RESULTS' / 'qc_reports.xlsx'\n",
        "\n",
        "if qc_file.exists():\n",
        "    qc = pd.read_excel(qc_file)\n",
        "    print(\"Quality Control Summary\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    if 'Overall_Status' in qc.columns:\n",
        "        status_counts = qc['Overall_Status'].value_counts()\n",
        "        print(f\"\\nStatus breakdown:\")\n",
        "        for status, count in status_counts.items():\n",
        "            print(f\"  {status}: {count}\")\n",
        "    \n",
        "    display(qc.head())\n",
        "else:\n",
        "    print(\"QC file not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Download Results\n",
        "\n",
        "Results are already saved in your Google Drive at:\n",
        "```\n",
        "MyDrive/RTpipeline/Output/_RESULTS/\n",
        "```\n",
        "\n",
        "You can also download specific files directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Download results to your local machine\n",
        "from google.colab import files\n",
        "\n",
        "results_dir = Path(OUTPUT_DIR) / '_RESULTS'\n",
        "\n",
        "# Uncomment to download specific files:\n",
        "# files.download(str(results_dir / 'dvh_metrics.xlsx'))\n",
        "# files.download(str(results_dir / 'radiomics_ct.xlsx'))\n",
        "# files.download(str(results_dir / 'qc_reports.xlsx'))\n",
        "\n",
        "print(\"To download files, uncomment the lines above and run this cell.\")\n",
        "print(f\"\\nOr access them directly in Google Drive at:\")\n",
        "print(f\"  {results_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"RTPIPELINE PROCESSING COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "results_path = output_path / '_RESULTS'\n",
        "\n",
        "# Count outputs\n",
        "patients = [d for d in output_path.iterdir() if d.is_dir() and not d.name.startswith('_')]\n",
        "courses = sum(1 for p in patients for c in p.iterdir() if c.is_dir())\n",
        "\n",
        "print(f\"\\nProcessed:\")\n",
        "print(f\"  Patients: {len(patients)}\")\n",
        "print(f\"  Treatment courses: {courses}\")\n",
        "\n",
        "print(f\"\\nResults location:\")\n",
        "print(f\"  {results_path}\")\n",
        "\n",
        "print(f\"\\nKey output files:\")\n",
        "if results_path.exists():\n",
        "    for f in sorted(results_path.glob('*.xlsx')):\n",
        "        print(f\"  - {f.name}\")\n",
        "\n",
        "print(f\"\\nLogs location:\")\n",
        "print(f\"  {LOGS_DIR}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Thank you for using RTpipeline!\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RTpipeline - Part 2: CPU Analysis\n",
        "\n",
        "**Radiotherapy DICOM Processing Pipeline - Colab Edition**\n",
        "\n",
        "This notebook runs CPU-intensive analysis tasks:\n",
        "- DVH (Dose-Volume Histogram) calculation\n",
        "- Radiomics feature extraction\n",
        "- Quality control reports\n",
        "- Results aggregation\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **Part 1 Complete**: Run `rtpipeline_colab_part1_gpu.ipynb` first\n",
        "2. **Runtime**: CPU runtime is sufficient (no GPU needed)\n",
        "3. **Time**: ~2-5 min per patient for full analysis\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Mount Google Drive and Load Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Google Drive mounted.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ### Load Configuration from Part 1 { display-mode: \"form\" }\n",
        "#@markdown **Configuration file location** (created by Part 1):\n",
        "CONFIG_PATH = \"/content/drive/MyDrive/RTpipeline/rtpipeline_config.yaml\"  #@param {type:\"string\"}\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Load configuration\n",
        "if os.path.exists(CONFIG_PATH):\n",
        "    with open(CONFIG_PATH, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    \n",
        "    # Extract key paths\n",
        "    DICOM_INPUT = config['dicom_root']\n",
        "    OUTPUT_DIR = config['output_dir']\n",
        "    LOGS_DIR = config['logs_dir']\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    print(\"CONFIGURATION LOADED FROM PART 1\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nInput:  {DICOM_INPUT}\")\n",
        "    print(f\"Output: {OUTPUT_DIR}\")\n",
        "    print(f\"Logs:   {LOGS_DIR}\")\n",
        "    print(f\"\\nRegion: {config.get('ct_cropping', {}).get('region', 'N/A')}\")\n",
        "    print(f\"CT Cropping: {config.get('ct_cropping', {}).get('enabled', False)}\")\n",
        "    print(f\"Robustness: {config.get('radiomics_robustness', {}).get('enabled', False)}\")\n",
        "    \n",
        "    # Verify Part 1 outputs exist\n",
        "    output_path = Path(OUTPUT_DIR)\n",
        "    if output_path.exists():\n",
        "        patients = [d for d in output_path.iterdir() if d.is_dir() and not d.name.startswith('_')]\n",
        "        seg_count = sum(1 for p in patients for c in p.iterdir() \n",
        "                        if c.is_dir() and (c / 'Segmentation_TotalSegmentator').exists())\n",
        "        print(f\"\\nPart 1 Status:\")\n",
        "        print(f\"  Patients: {len(patients)}\")\n",
        "        print(f\"  Segmented courses: {seg_count}\")\n",
        "        \n",
        "        if seg_count > 0:\n",
        "            print(\"\\n✅ Part 1 data found. Ready to continue.\")\n",
        "        else:\n",
        "            print(\"\\n⚠️  WARNING: No segmentations found!\")\n",
        "            print(\"   Please run Part 1 first.\")\n",
        "    else:\n",
        "        print(f\"\\n❌ Output directory not found: {OUTPUT_DIR}\")\n",
        "        print(\"   Please run Part 1 first.\")\n",
        "else:\n",
        "    print(f\"❌ Configuration file not found: {CONFIG_PATH}\")\n",
        "    print(\"\\nPlease run Part 1 first to generate the configuration.\")\n",
        "    print(\"Or update the CONFIG_PATH above to point to your config file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Install Miniconda (if not already installed)\n",
        "if [ ! -d \"/content/miniconda\" ]; then\n",
        "    echo \"Installing Miniconda...\"\n",
        "    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "    bash miniconda.sh -b -p /content/miniconda\n",
        "    rm miniconda.sh\n",
        "    echo \"Miniconda installed.\"\n",
        "else\n",
        "    echo \"Miniconda already installed.\"\n",
        "fi\n",
        "\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Install mamba\n",
        "if ! command -v mamba &> /dev/null; then\n",
        "    echo \"Installing mamba...\"\n",
        "    conda install -y -c conda-forge mamba\n",
        "fi\n",
        "\n",
        "echo \"Done.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PATH'] = '/content/miniconda/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Clone/update rtpipeline\n",
        "if [ ! -d \"/content/rtpipeline\" ]; then\n",
        "    echo \"Cloning rtpipeline...\"\n",
        "    git clone https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n",
        "else\n",
        "    echo \"Updating rtpipeline...\"\n",
        "    cd /content/rtpipeline && git pull\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Create rtpipeline-radiomics environment (PyRadiomics requires NumPy 1.x)\n",
        "if ! conda env list | grep -q \"rtpipeline-radiomics\"; then\n",
        "    echo \"Creating rtpipeline-radiomics environment (this takes ~10 minutes)...\"\n",
        "    mamba env create -f /content/rtpipeline/envs/rtpipeline-radiomics.yaml\n",
        "    echo \"Environment created.\"\n",
        "else\n",
        "    echo \"rtpipeline-radiomics environment already exists.\"\n",
        "fi\n",
        "\n",
        "# Also ensure main environment exists for DVH\n",
        "if ! conda env list | grep -q \"^rtpipeline \"; then\n",
        "    echo \"Creating rtpipeline environment...\"\n",
        "    mamba env create -f /content/rtpipeline/envs/rtpipeline.yaml\n",
        "fi\n",
        "\n",
        "# Install rtpipeline package in both environments\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "\n",
        "conda activate rtpipeline\n",
        "pip install -e /content/rtpipeline 2>/dev/null || true\n",
        "\n",
        "conda activate rtpipeline-radiomics\n",
        "pip install -e /content/rtpipeline 2>/dev/null || true\n",
        "\n",
        "echo \"\\nEnvironments ready!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Copy Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Copy configuration to local rtpipeline directory\n",
        "local_config = '/content/rtpipeline/config.colab.yaml'\n",
        "shutil.copy(CONFIG_PATH, local_config)\n",
        "\n",
        "print(f\"Configuration copied to: {local_config}\")\n",
        "print(f\"\\nReady to run analysis pipeline.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Run DVH Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"================================================\"\n",
        "echo \"Running DVH Calculation\"\n",
        "echo \"================================================\"\n",
        "\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    --until all_dvh \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee -a \"$(cat config.colab.yaml | grep logs_dir | cut -d':' -f2 | tr -d ' ')/part2_dvh.log\"\n",
        "\n",
        "echo \"\\n✅ DVH calculation complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Run Radiomics Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline-radiomics\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"================================================\"\n",
        "echo \"Running Radiomics Extraction\"\n",
        "echo \"================================================\"\n",
        "echo \"(This may take several minutes per patient)\"\n",
        "\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    --until all_radiomics \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee -a \"$(cat config.colab.yaml | grep logs_dir | cut -d':' -f2 | tr -d ' ')/part2_radiomics.log\"\n",
        "\n",
        "echo \"\\n✅ Radiomics extraction complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Run Quality Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"================================================\"\n",
        "echo \"Running Quality Control\"\n",
        "echo \"================================================\"\n",
        "\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    --until all_qc \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee -a \"$(cat config.colab.yaml | grep logs_dir | cut -d':' -f2 | tr -d ' ')/part2_qc.log\"\n",
        "\n",
        "echo \"\\n✅ Quality control complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Aggregate All Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "source /content/miniconda/etc/profile.d/conda.sh\n",
        "conda activate rtpipeline\n",
        "\n",
        "cd /content/rtpipeline\n",
        "\n",
        "echo \"================================================\"\n",
        "echo \"Aggregating All Results\"\n",
        "echo \"================================================\"\n",
        "\n",
        "snakemake \\\n",
        "    --cores 2 \\\n",
        "    --configfile config.colab.yaml \\\n",
        "    all \\\n",
        "    --rerun-incomplete \\\n",
        "    2>&1 | tee -a \"$(cat config.colab.yaml | grep logs_dir | cut -d':' -f2 | tr -d ' ')/part2_aggregate.log\"\n",
        "\n",
        "echo \"\\n✅ Aggregation complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "results_dir = Path(OUTPUT_DIR) / '_RESULTS'\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PIPELINE RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if results_dir.exists():\n",
        "    print(f\"\\nResults directory: {results_dir}\")\n",
        "    print(\"\\nAvailable files:\")\n",
        "    for f in sorted(results_dir.glob('*.xlsx')):\n",
        "        size_mb = f.stat().st_size / 1e6\n",
        "        print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
        "else:\n",
        "    print(f\"Results directory not found: {results_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preview DVH metrics\n",
        "dvh_file = Path(OUTPUT_DIR) / '_RESULTS' / 'dvh_metrics.xlsx'\n",
        "\n",
        "if dvh_file.exists():\n",
        "    dvh = pd.read_excel(dvh_file)\n",
        "    print(\"DVH METRICS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Rows: {len(dvh)}\")\n",
        "    print(f\"Structures: {dvh['Structure'].nunique()}\")\n",
        "    print(f\"Patients: {dvh['PatientID'].nunique()}\")\n",
        "    print(f\"\\nColumns: {list(dvh.columns)[:10]}...\")\n",
        "    print(\"\\nSample data:\")\n",
        "    display(dvh.head(10))\n",
        "else:\n",
        "    print(\"DVH metrics file not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preview radiomics features\n",
        "radiomics_file = Path(OUTPUT_DIR) / '_RESULTS' / 'radiomics_ct.xlsx'\n",
        "\n",
        "if radiomics_file.exists():\n",
        "    rad = pd.read_excel(radiomics_file)\n",
        "    print(\"RADIOMICS FEATURES\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Rows: {len(rad)}\")\n",
        "    print(f\"Features: {len(rad.columns)}\")\n",
        "    \n",
        "    if 'Structure' in rad.columns:\n",
        "        print(f\"Structures: {rad['Structure'].nunique()}\")\n",
        "    \n",
        "    # Count feature types\n",
        "    original = len([c for c in rad.columns if c.startswith('original_')])\n",
        "    wavelet = len([c for c in rad.columns if c.startswith('wavelet')])\n",
        "    log = len([c for c in rad.columns if c.startswith('log-sigma')])\n",
        "    print(f\"\\nFeature breakdown:\")\n",
        "    print(f\"  Original: {original}\")\n",
        "    print(f\"  Wavelet: {wavelet}\")\n",
        "    print(f\"  LoG: {log}\")\n",
        "else:\n",
        "    print(\"Radiomics file not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check QC summary\n",
        "qc_file = Path(OUTPUT_DIR) / '_RESULTS' / 'qc_reports.xlsx'\n",
        "\n",
        "if qc_file.exists():\n",
        "    qc = pd.read_excel(qc_file)\n",
        "    print(\"QUALITY CONTROL SUMMARY\")\n",
        "    print(\"=\"*40)\n",
        "    \n",
        "    if 'Overall_Status' in qc.columns:\n",
        "        status_counts = qc['Overall_Status'].value_counts()\n",
        "        print(f\"\\nStatus breakdown:\")\n",
        "        for status, count in status_counts.items():\n",
        "            print(f\"  {status}: {count}\")\n",
        "    \n",
        "    print(\"\\nSample data:\")\n",
        "    display(qc.head())\n",
        "else:\n",
        "    print(\"QC file not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Download Results\n",
        "\n",
        "Results are saved in your Google Drive at the output directory.\n",
        "\n",
        "You can also download specific files directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Download results to your local machine\n",
        "from google.colab import files\n",
        "\n",
        "results_dir = Path(OUTPUT_DIR) / '_RESULTS'\n",
        "\n",
        "print(\"To download files, uncomment the lines below and run this cell.\")\n",
        "print(f\"\\nResults are already saved in Google Drive at:\")\n",
        "print(f\"  {results_dir}\")\n",
        "\n",
        "# Uncomment to download specific files:\n",
        "# files.download(str(results_dir / 'dvh_metrics.xlsx'))\n",
        "# files.download(str(results_dir / 'radiomics_ct.xlsx'))\n",
        "# files.download(str(results_dir / 'qc_reports.xlsx'))\n",
        "# files.download(str(results_dir / 'case_metadata.xlsx'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10. Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RTPIPELINE PROCESSING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "results_path = output_path / '_RESULTS'\n",
        "\n",
        "# Count outputs\n",
        "patients = [d for d in output_path.iterdir() if d.is_dir() and not d.name.startswith('_')]\n",
        "courses = sum(1 for p in patients for c in p.iterdir() if c.is_dir())\n",
        "\n",
        "print(f\"\\nProcessed:\")\n",
        "print(f\"  Patients: {len(patients)}\")\n",
        "print(f\"  Treatment courses: {courses}\")\n",
        "\n",
        "print(f\"\\nResults location:\")\n",
        "print(f\"  {results_path}\")\n",
        "\n",
        "print(f\"\\nKey output files:\")\n",
        "if results_path.exists():\n",
        "    for f in sorted(results_path.glob('*.xlsx')):\n",
        "        print(f\"  - {f.name}\")\n",
        "\n",
        "print(f\"\\nConfiguration used:\")\n",
        "print(f\"  {CONFIG_PATH}\")\n",
        "\n",
        "print(f\"\\nLogs location:\")\n",
        "print(f\"  {LOGS_DIR}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Thank you for using RTpipeline!\")\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}

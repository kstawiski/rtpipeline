{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTpipeline on Google Colab - Part 2: CPU Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kstawiski/rtpipeline/blob/main/rtpipeline_colab_part2_cpu.ipynb)\n",
    "\n",
    "**ğŸ’° Cost Optimization:** This notebook runs on **CPU ONLY** (no GPU needed)!\n",
    "\n",
    "## What This Part Does\n",
    "\n",
    "âœ… **Loads segmentations** from Part 1\n",
    "âœ… **DVH extraction** (dose-volume histogram metrics)\n",
    "âœ… **Radiomics features** (150+ texture/shape features)\n",
    "âœ… **Robustness testing** (optional - feature stability)\n",
    "âœ… **Aggregation and visualization**\n",
    "âœ… **Downloadable results**\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Part 1 (GPU segmentation)\n",
    "- Part 1 outputs saved to Google Drive\n",
    "- **CPU runtime** (Runtime â†’ Change runtime type â†’ None/CPU)\n",
    "\n",
    "---\n",
    "\n",
    "**âš¡ Quick Start:**\n",
    "1. Run cells 1-3 (setup)\n",
    "2. Mount Google Drive (cell 4)\n",
    "3. **UPDATE CONFIGURATION** (cell 5) - Point to Part 1 output folder\n",
    "4. Run remaining cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup: Install Miniconda & System Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Installing System Dependencies ===\"\n",
    "apt-get update -qq\n",
    "apt-get install -y -qq dcm2niix pigz > /dev/null\n",
    "\n",
    "if [ ! -d \"/content/miniconda\" ]; then\n",
    "    echo -e \"\\n=== Installing Miniconda ===\"\n",
    "    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh\n",
    "    bash /tmp/miniconda.sh -b -p /content/miniconda\n",
    "    rm /tmp/miniconda.sh\n",
    "    echo \"âœ… Miniconda installed\"\n",
    "else\n",
    "    echo \"âœ… Miniconda already installed\"\n",
    "fi\n",
    "\n",
    "export PATH=\"/content/miniconda/bin:$PATH\"\n",
    "eval \"$(/content/miniconda/bin/conda shell.bash hook)\"\n",
    "conda init bash\n",
    "\n",
    "echo -e \"\\nâœ… Setup complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Clone RTpipeline Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d \"/content/rtpipeline\" ]; then\n",
    "    echo \"Cloning rtpipeline repository...\"\n",
    "    git clone -q https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n",
    "    echo \"âœ… Repository cloned\"\n",
    "else\n",
    "    echo \"âœ… Repository already exists\"\n",
    "    cd /content/rtpipeline\n",
    "    git pull origin main\n",
    "    echo \"Repository updated\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Create Conda Environments\n",
    "\n",
    "Creates two environments (~5-10 minutes, only once per session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PATH=\"/content/miniconda/bin:$PATH\"\n",
    "eval \"$(/content/miniconda/bin/conda shell.bash hook)\"\n",
    "\n",
    "echo \"=== Accepting Anaconda Terms of Service ===\"\n",
    "conda config --set channel_priority flexible\n",
    "if ! conda tos accept --channel defaults 2>&1; then\n",
    "    echo \"âš ï¸ ToS acceptance failed or already accepted\"\n",
    "fi\n",
    "\n",
    "cd /content/rtpipeline\n",
    "\n",
    "if conda env list | grep -q \"^rtpipeline \"; then\n",
    "    echo \"âœ… Environment 'rtpipeline' exists\"\n",
    "else\n",
    "    echo \"Creating 'rtpipeline' environment...\"\n",
    "    conda env create -f envs/rtpipeline.yaml -q\n",
    "    echo \"âœ… Created\"\n",
    "fi\n",
    "\n",
    "if conda env list | grep -q \"^rtpipeline-radiomics \"; then\n",
    "    echo \"âœ… Environment 'rtpipeline-radiomics' exists\"\n",
    "else\n",
    "    echo \"Creating 'rtpipeline-radiomics' environment...\"\n",
    "    conda env create -f envs/rtpipeline-radiomics.yaml -q\n",
    "    echo \"âœ… Created\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"âœ… Environments ready\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\nâœ… Google Drive mounted at /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âš™ï¸ CONFIGURATION - UPDATE THIS!\n",
    "\n",
    "## 5ï¸âƒ£ Configure Part 1 Output Path & Processing Options\n",
    "\n",
    "**ğŸ”´ REQUIRED:** Update `PART1_OUTPUT_DIR`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import multiprocessing\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”´ REQUIRED - Point to Part 1 output in Google Drive\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PART1_OUTPUT_DIR = \"/content/drive/MyDrive/rtpipeline_part1_output_20250101_120000\"\n",
    "\n",
    "# Check README_PART2.txt from Part 1 for the exact path\n",
    "# Format: /content/drive/MyDrive/rtpipeline_part1_output_YYYYMMDD_HHMMSS\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Parallelism & Performance Settings\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Snakemake workers (course-level parallelism)\n",
    "# Google Colab CPU: Can use more workers than GPU version\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "WORKERS = min(CPU_COUNT, 8)  # Auto-detect, max 8 (4-8 recommended)\n",
    "\n",
    "# DVH extraction parallelism\n",
    "# Each course DVH extraction can use multiple threads\n",
    "DVH_THREADS_PER_COURSE = 2  # Threads for parallel DVH calculation (1-4 recommended)\n",
    "\n",
    "# Radiomics parallelism\n",
    "RADIOMICS_THREAD_LIMIT = 4  # Thread limit for PyRadiomics (2-6 recommended)\n",
    "RADIOMICS_SEQUENTIAL = False  # Set True if memory issues occur\n",
    "\n",
    "# Aggregation parallelism\n",
    "AGGREGATION_THREADS = \"auto\"  # \"auto\" or specific number (e.g., 4)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Analysis Options\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Enable/disable analysis components\n",
    "ENABLE_DVH = True  # DVH metrics extraction\n",
    "ENABLE_RADIOMICS = True  # Radiomic feature extraction\n",
    "ENABLE_ROBUSTNESS = False  # Robustness testing (adds 10-30 min)\n",
    "ENABLE_QC = True  # Quality control metrics\n",
    "\n",
    "# Radiomics ROI filtering\n",
    "RADIOMICS_SKIP_ROIS = [\"body\", \"couchsurface\", \"bones\"]  # Skip these ROIs\n",
    "RADIOMICS_MAX_VOXELS = 1500000000  # Skip ROIs larger than this\n",
    "RADIOMICS_MIN_VOXELS = 10  # Skip ROIs smaller than this\n",
    "\n",
    "# Radiomics parameters file\n",
    "RADIOMICS_PARAMS_CT = \"/content/rtpipeline/rtpipeline/radiomics_params.yaml\"\n",
    "RADIOMICS_PARAMS_MR = \"/content/rtpipeline/rtpipeline/radiomics_params_mr.yaml\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Robustness Testing Configuration (if enabled)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ROBUSTNESS_STRUCTURES = [\n",
    "    \"GTV*\", \"CTV*\", \"PTV*\",\n",
    "    \"urinary_bladder\", \"rectum\", \"prostate\"\n",
    "]  # Wildcard patterns for structures to test\n",
    "\n",
    "ROBUSTNESS_INTENSITY = \"standard\"  # Options: \"mild\", \"standard\", \"aggressive\"\n",
    "\n",
    "# Perturbation parameters (standard preset)\n",
    "ROBUSTNESS_VOLUME_CHANGES = [-0.15, 0.0, 0.15]  # Â±15% volume changes\n",
    "ROBUSTNESS_TRANSLATIONS_MM = 0.0  # 0 = disabled, 3.0 or 5.0 to enable\n",
    "ROBUSTNESS_NOISE_LEVELS = [0.0]  # [0.0, 10.0, 20.0] to test noise\n",
    "ROBUSTNESS_CONTOUR_REALIZATIONS = 0  # 0 = disabled, 2-3 to enable\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Custom Structures Configuration\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "CUSTOM_STRUCTURES_FILE = \"custom_structures_pelvic.yaml\"\n",
    "# Options: \"custom_structures_pelvic.yaml\", \"custom_structures_thorax.yaml\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Validation & Setup\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "OUTPUT_DIR = \"/content/output\"\n",
    "LOGS_DIR = \"/content/logs\"\n",
    "\n",
    "if not os.path.exists(PART1_OUTPUT_DIR):\n",
    "    print(\"ğŸ”´ ERROR: Part 1 output not found!\")\n",
    "    print(f\"   Path: {PART1_OUTPUT_DIR}\")\n",
    "    print(\"\\n   Please:\")\n",
    "    print(\"   1. Complete Part 1 first\")\n",
    "    print(\"   2. Update PART1_OUTPUT_DIR above\")\n",
    "    print(\"   3. Check README_PART2.txt from Part 1\")\n",
    "else:\n",
    "    manifest_path = f\"{PART1_OUTPUT_DIR}/_COURSES/manifest.json\"\n",
    "    if not os.path.exists(manifest_path):\n",
    "        print(\"âš ï¸ WARNING: Not a valid Part 1 output (missing manifest)\")\n",
    "    else:\n",
    "        print(\"âœ… Part 1 outputs found\")\n",
    "        print(f\"   {PART1_OUTPUT_DIR}\")\n",
    "        \n",
    "        print(\"\\nCopying outputs to local directory...\")\n",
    "        if os.path.exists(OUTPUT_DIR):\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "        shutil.copytree(PART1_OUTPUT_DIR, OUTPUT_DIR)\n",
    "        \n",
    "        import glob\n",
    "        courses = []\n",
    "        for patient_dir in glob.glob(f\"{OUTPUT_DIR}/*/\"):\n",
    "            patient_name = os.path.basename(patient_dir.rstrip('/'))\n",
    "            if patient_name.startswith('_') or patient_name.startswith('.'):\n",
    "                continue\n",
    "            for course_dir in glob.glob(f\"{patient_dir}/*/\"):\n",
    "                course_name = os.path.basename(course_dir.rstrip('/'))\n",
    "                if not course_name.startswith('_'):\n",
    "                    courses.append(f\"{patient_name}/{course_name}\")\n",
    "        \n",
    "        print(f\"\\nâœ… Copied! Found {len(courses)} course(s)\")\n",
    "        if courses:\n",
    "            for c in courses[:3]:\n",
    "                print(f\"  - {c}\")\n",
    "            if len(courses) > 3:\n",
    "                print(f\"  ... and {len(courses) - 3} more\")\n",
    "\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load DICOM root from Part 1 config\n",
    "part1_config = f\"{OUTPUT_DIR}/config_part1.yaml\"\n",
    "DICOM_ROOT = \"/content/drive/MyDrive/my_dicom_folder\"  # default\n",
    "if os.path.exists(part1_config):\n",
    "    with open(part1_config, 'r') as f:\n",
    "        import re\n",
    "        content = f.read()\n",
    "        match = re.search(r'dicom_root:\\s*\"([^\"]+)\"', content)\n",
    "        if match:\n",
    "            DICOM_ROOT = match.group(1)\n",
    "            print(f\"\\nâœ… DICOM root from Part 1: {DICOM_ROOT}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Configuration Summary:\")\n",
    "print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(f\"   CPU cores: {CPU_COUNT}\")\n",
    "print(f\"   Snakemake workers: {WORKERS}\")\n",
    "print(f\"   Parallelism:\")\n",
    "print(f\"     â€¢ DVH threads/course: {DVH_THREADS_PER_COURSE}\")\n",
    "print(f\"     â€¢ Radiomics thread limit: {RADIOMICS_THREAD_LIMIT}\")\n",
    "print(f\"     â€¢ Radiomics sequential: {RADIOMICS_SEQUENTIAL}\")\n",
    "print(f\"     â€¢ Aggregation: {AGGREGATION_THREADS}\")\n",
    "print(f\"   Components:\")\n",
    "print(f\"     â€¢ DVH: {'âœ…' if ENABLE_DVH else 'âŒ'}\")\n",
    "print(f\"     â€¢ Radiomics: {'âœ…' if ENABLE_RADIOMICS else 'âŒ'}\")\n",
    "print(f\"     â€¢ Robustness: {'âœ…' if ENABLE_ROBUSTNESS else 'âŒ'}\")\n",
    "print(f\"     â€¢ QC: {'âœ…' if ENABLE_QC else 'âŒ'}\")\n",
    "print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "\n",
    "# Parallelism recommendations\n",
    "if WORKERS * RADIOMICS_THREAD_LIMIT > CPU_COUNT * 2:\n",
    "    print(f\"\\nâš ï¸ NOTE: Total thread usage may exceed CPU cores\")\n",
    "    print(f\"   Consider reducing WORKERS or RADIOMICS_THREAD_LIMIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6ï¸âƒ£ Generate Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml = f\"\"\"# RTpipeline Configuration - Part 2 (CPU Analysis)\n",
    "dicom_root: \"{DICOM_ROOT}\"\n",
    "output_dir: \"{OUTPUT_DIR}\"\n",
    "logs_dir: \"{LOGS_DIR}\"\n",
    "workers: {WORKERS}\n",
    "\n",
    "dvh:\n",
    "  threads_per_course: {DVH_THREADS_PER_COURSE}\n",
    "\n",
    "radiomics:\n",
    "  sequential: {str(RADIOMICS_SEQUENTIAL).lower()}\n",
    "  params_file: \"{RADIOMICS_PARAMS_CT}\"\n",
    "  mr_params_file: \"{RADIOMICS_PARAMS_MR}\"\n",
    "  thread_limit: {RADIOMICS_THREAD_LIMIT}\n",
    "  skip_rois: {RADIOMICS_SKIP_ROIS}\n",
    "  max_voxels: {RADIOMICS_MAX_VOXELS}\n",
    "  min_voxels: {RADIOMICS_MIN_VOXELS}\n",
    "\n",
    "radiomics_robustness:\n",
    "  enabled: {str(ENABLE_ROBUSTNESS).lower()}\n",
    "  structures: {ROBUSTNESS_STRUCTURES if ENABLE_ROBUSTNESS else '[]'}\n",
    "  intensity: \"{ROBUSTNESS_INTENSITY}\"\n",
    "  volume_changes: {ROBUSTNESS_VOLUME_CHANGES if ENABLE_ROBUSTNESS else '[]'}\n",
    "  translations_mm: {ROBUSTNESS_TRANSLATIONS_MM}\n",
    "  noise_levels: {ROBUSTNESS_NOISE_LEVELS if ENABLE_ROBUSTNESS else '[]'}\n",
    "  contour_realizations: {ROBUSTNESS_CONTOUR_REALIZATIONS}\n",
    "\n",
    "aggregation:\n",
    "  threads: {AGGREGATION_THREADS if isinstance(AGGREGATION_THREADS, int) else f'\"{AGGREGATION_THREADS}\"'}\n",
    "\n",
    "custom_structures: \"{CUSTOM_STRUCTURES_FILE}\"\n",
    "\"\"\"\n",
    "\n",
    "config_path = \"/content/config_part2.yaml\"\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_yaml)\n",
    "\n",
    "print(f\"âœ… Configuration written to: {config_path}\")\n",
    "print(f\"\\nReview configuration: !cat {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Run Part 2 Pipeline\n",
    "\n",
    "â±ï¸ **Estimated Time:**\n",
    "- DVH only: 5-15 minutes\n",
    "- DVH + Radiomics: 20-45 minutes\n",
    "- DVH + Radiomics + Robustness: 30-90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "os.environ['PATH'] = f\"/content/miniconda/bin:{os.environ.get('PATH', '')}\"\n",
    "os.chdir('/content/rtpipeline')\n",
    "\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"   RTpipeline Part 2: CPU Analysis\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"\\nâš¡ Processing:\")\n",
    "if ENABLE_DVH:\n",
    "    print(f\"   âœ“ DVH extraction ({DVH_THREADS_PER_COURSE} threads/course)\")\n",
    "if ENABLE_RADIOMICS:\n",
    "    print(f\"   âœ“ Radiomics (thread limit: {RADIOMICS_THREAD_LIMIT})\")\n",
    "if ENABLE_ROBUSTNESS:\n",
    "    print(f\"   âœ“ Robustness testing ({ROBUSTNESS_INTENSITY})\")\n",
    "if ENABLE_QC:\n",
    "    print(\"   âœ“ Quality control\")\n",
    "print(f\"   âœ“ Aggregation\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Install Snakemake\n",
    "try:\n",
    "    subprocess.run([\"conda\", \"run\", \"-n\", \"base\", \"snakemake\", \"--version\"],\n",
    "                   check=True, capture_output=True)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Installing Snakemake...\")\n",
    "    subprocess.run([\"conda\", \"install\", \"-n\", \"base\", \"-c\", \"conda-forge\",\n",
    "                    \"-c\", \"bioconda\", \"snakemake\", \"-y\", \"-q\"], check=True)\n",
    "    print(\"âœ… Snakemake installed\\n\")\n",
    "\n",
    "# Run pipeline\n",
    "cmd = [\n",
    "    \"conda\", \"run\", \"-n\", \"base\", \"snakemake\",\n",
    "    \"--configfile\", \"/content/config_part2.yaml\",\n",
    "    \"--use-conda\",\n",
    "    \"--cores\", str(WORKERS),\n",
    "    \"--printshellcmds\",\n",
    "    \"--keep-going\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=False, text=True)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… Part 2 Complete!\")\n",
    "else:\n",
    "    print(\"âš ï¸ Completed with some errors\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total time: {total_time/60:.1f} minutes\")\n",
    "print(f\"\\nResults: {OUTPUT_DIR}/_RESULTS/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "results_dir = f\"{OUTPUT_DIR}/_RESULTS\"\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    print(\"âš ï¸ Results directory not found\")\n",
    "else:\n",
    "    print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "    print(\"   Results Summary\")\n",
    "    print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "    \n",
    "    files = [f for f in os.listdir(results_dir) if f.endswith('.xlsx')]\n",
    "    print(f\"Generated {len(files)} files:\\n\")\n",
    "    for f in files:\n",
    "        size_mb = os.path.getsize(os.path.join(results_dir, f)) / 1024 / 1024\n",
    "        print(f\"  âœ“ {f} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Load results\n",
    "    try:\n",
    "        dvh = pd.read_excel(os.path.join(results_dir, \"dvh_metrics.xlsx\"))\n",
    "        print(f\"\\nğŸ“Š DVH: {len(dvh)} rows\")\n",
    "        print(f\"   Structures: {', '.join(dvh['Structure'].value_counts().head(5).index.tolist())}\")\n",
    "        globals()['dvh'] = dvh\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if ENABLE_RADIOMICS:\n",
    "        try:\n",
    "            radiomics = pd.read_excel(os.path.join(results_dir, \"radiomics_ct.xlsx\"))\n",
    "            print(f\"\\nğŸ”¬ Radiomics: {len(radiomics)} rows, {len(radiomics.columns)} features\")\n",
    "            globals()['radiomics'] = radiomics\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if ENABLE_ROBUSTNESS:\n",
    "        try:\n",
    "            rob = pd.read_excel(os.path.join(results_dir, \"radiomics_robustness_summary.xlsx\"),\n",
    "                               sheet_name='global_summary')\n",
    "            print(f\"\\nğŸ¯ Robustness: {len(rob)} features\")\n",
    "            print(f\"   {rob['robustness_label'].value_counts().to_dict()}\")\n",
    "            globals()['robustness_summary'] = rob\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"\\nâœ… Results loaded: dvh, radiomics, robustness_summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "if 'dvh' in globals():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    top_structures = dvh.groupby('Structure')['Dmean_Gy'].mean().sort_values(ascending=False).head(10)\n",
    "    top_structures.plot(kind='barh', ax=axes[0], color='steelblue')\n",
    "    axes[0].set_xlabel('Mean Dose (Gy)')\n",
    "    axes[0].set_title('Top 10 Structures by Mean Dose')\n",
    "    \n",
    "    dvh['ROI_Volume_cc'].hist(bins=50, ax=axes[1], color='coral', edgecolor='black')\n",
    "    axes[1].set_xlabel('ROI Volume (cc)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('ROI Volume Distribution')\n",
    "    axes[1].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"âœ… DVH visualizations\")\n",
    "else:\n",
    "    print(\"âš ï¸ No DVH data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content\n",
    "zip -r -q results.zip output/_RESULTS/\n",
    "echo \"âœ… Archive: /content/results.zip\"\n",
    "ls -lh /content/results.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('/content/results.zip')\n",
    "print(\"\\nâœ… Download started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "drive_results = f\"/content/drive/MyDrive/rtpipeline_results_{timestamp}\"\n",
    "\n",
    "try:\n",
    "    shutil.copytree(f\"{OUTPUT_DIR}/_RESULTS\", drive_results)\n",
    "    files = [f for f in os.listdir(drive_results) if f.endswith('.xlsx')]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ ALL DONE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nSaved to: {drive_results}\")\n",
    "    print(f\"\\n{len(files)} files:\")\n",
    "    for f in files:\n",
    "        print(f\"  âœ“ {f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ Complete!\n",
    "\n",
    "**What you have:**\n",
    "- âœ… DVH metrics\n",
    "- âœ… Radiomic features\n",
    "- âœ… Robustness analysis (if enabled)\n",
    "- âœ… Analysis-ready data\n",
    "\n",
    "**ğŸ’° Cost Savings:** GPU used only for Part 1 segmentation!\n",
    "\n",
    "---\n",
    "\n",
    "**Resources:**\n",
    "- [Output Format Guide](https://github.com/kstawiski/rtpipeline/blob/main/output_format.md)\n",
    "- [Robustness Guide](https://github.com/kstawiski/rtpipeline/blob/main/RADIOMICS_ROBUSTNESS.md)\n",
    "- [Repository](https://github.com/kstawiski/rtpipeline)\n",
    "\n",
    "**Version:** 2.0 (Part 2 - CPU Analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

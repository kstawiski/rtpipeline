{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTpipeline on Google Colab - Part 2: CPU Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kstawiski/rtpipeline/blob/main/rtpipeline_colab_part2_cpu.ipynb)\n",
    "\n",
    "**ğŸ’° Cost Optimization:** This notebook runs on **CPU ONLY** (no GPU needed)!\n",
    "\n",
    "## What This Part Does\n",
    "\n",
    "âœ… **Loads segmentations** from Part 1\n",
    "âœ… **DVH extraction** (dose-volume histogram metrics)\n",
    "âœ… **Radiomics features** (150+ texture/shape features)\n",
    "âœ… **Robustness testing** (optional - feature stability)\n",
    "âœ… **Aggregation and visualization**\n",
    "âœ… **Downloadable results**\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Part 1 (GPU segmentation)\n",
    "- Part 1 outputs saved to Google Drive\n",
    "- **CPU runtime** (Runtime â†’ Change runtime type â†’ None/CPU)\n",
    "\n",
    "---\n",
    "\n",
    "**âš¡ Quick Start:**\n",
    "1. Run cells 1-3 (setup)\n",
    "2. Mount Google Drive (cell 4)\n",
    "3. **UPDATE CONFIGURATION** (cell 5) - Point to Part 1 output folder\n",
    "4. Run remaining cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup: Install Miniconda & System Dependencies\n",
    "\n",
    "This takes ~2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install system dependencies\n",
    "echo \"=== Installing System Dependencies ===\"\n",
    "apt-get update -qq\n",
    "apt-get install -y -qq dcm2niix pigz > /dev/null\n",
    "\n",
    "# Install Miniconda\n",
    "if [ ! -d \"/content/miniconda\" ]; then\n",
    "    echo -e \"\\n=== Installing Miniconda ===\"\n",
    "    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh\n",
    "    bash /tmp/miniconda.sh -b -p /content/miniconda\n",
    "    rm /tmp/miniconda.sh\n",
    "    echo \"âœ… Miniconda installed\"\n",
    "else\n",
    "    echo \"âœ… Miniconda already installed\"\n",
    "fi\n",
    "\n",
    "# Initialize conda\n",
    "export PATH=\"/content/miniconda/bin:$PATH\"\n",
    "eval \"$(/content/miniconda/bin/conda shell.bash hook)\"\n",
    "conda init bash\n",
    "\n",
    "echo -e \"\\nâœ… Setup complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Clone RTpipeline Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d \"/content/rtpipeline\" ]; then\n",
    "    echo \"Cloning rtpipeline repository...\"\n",
    "    git clone -q https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n",
    "    echo \"âœ… Repository cloned\"\n",
    "else\n",
    "    echo \"âœ… Repository already exists\"\n",
    "    cd /content/rtpipeline\n",
    "    git pull origin main\n",
    "    echo \"Repository updated\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Create Conda Environments\n",
    "\n",
    "This creates two environments (~5-10 minutes, only once per session):\n",
    "- **rtpipeline**: For DVH extraction\n",
    "- **rtpipeline-radiomics**: For PyRadiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PATH=\"/content/miniconda/bin:$PATH\"\n",
    "eval \"$(/content/miniconda/bin/conda shell.bash hook)\"\n",
    "\n",
    "# Accept ToS\n",
    "echo \"=== Accepting Anaconda Terms of Service ===\"\n",
    "conda config --set channel_priority flexible\n",
    "if ! conda tos accept --channel defaults 2>&1; then\n",
    "    echo \"âš ï¸ ToS acceptance failed or already accepted\"\n",
    "fi\n",
    "echo \"âœ… ToS accepted\"\n",
    "\n",
    "cd /content/rtpipeline\n",
    "\n",
    "# Create rtpipeline environment\n",
    "if conda env list | grep -q \"^rtpipeline \"; then\n",
    "    echo \"âœ… Environment 'rtpipeline' exists\"\n",
    "else\n",
    "    echo \"Creating 'rtpipeline' environment...\"\n",
    "    conda env create -f envs/rtpipeline.yaml -q\n",
    "    echo \"âœ… Created\"\n",
    "fi\n",
    "\n",
    "# Create rtpipeline-radiomics environment\n",
    "if conda env list | grep -q \"^rtpipeline-radiomics \"; then\n",
    "    echo \"âœ… Environment 'rtpipeline-radiomics' exists\"\n",
    "else\n",
    "    echo \"Creating 'rtpipeline-radiomics' environment...\"\n",
    "    conda env create -f envs/rtpipeline-radiomics.yaml -q\n",
    "    echo \"âœ… Created\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"âœ… Environments ready\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Mount Google Drive\n",
    "\n",
    "**IMPORTANT:** Part 1 outputs must be in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\nâœ… Google Drive mounted at /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âš™ï¸ CONFIGURATION - UPDATE THIS!\n",
    "\n",
    "## 5ï¸âƒ£ Configure Part 1 Output Path\n",
    "\n",
    "**ğŸ”´ REQUIRED:** Update `PART1_OUTPUT_DIR` to point to your Part 1 output folder in Google Drive\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”´ UPDATE THIS - Point to your Part 1 output in Google Drive\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PART1_OUTPUT_DIR = \"/content/drive/MyDrive/rtpipeline_part1_output_20250101_120000\"\n",
    "\n",
    "# The path format is usually:\n",
    "# /content/drive/MyDrive/rtpipeline_part1_output_YYYYMMDD_HHMMSS\n",
    "#\n",
    "# Check the README_PART2.txt file from Part 1 for the exact path\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Processing Options\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "WORKERS = 4                  # CPU workers (4-8 recommended)\n",
    "ENABLE_RADIOMICS = True      # Extract radiomic features\n",
    "ENABLE_ROBUSTNESS = False    # Robustness testing (adds 10-30 min)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Validation and Setup\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Local working directories\n",
    "OUTPUT_DIR = \"/content/output\"\n",
    "LOGS_DIR = \"/content/logs\"\n",
    "\n",
    "# Check Part 1 outputs\n",
    "if not os.path.exists(PART1_OUTPUT_DIR):\n",
    "    print(\"ğŸ”´ ERROR: Part 1 output directory not found!\")\n",
    "    print(f\"   Path: {PART1_OUTPUT_DIR}\")\n",
    "    print(\"\\n   Please:\")\n",
    "    print(\"   1. Check that you completed Part 1\")\n",
    "    print(\"   2. Update PART1_OUTPUT_DIR above\")\n",
    "    print(\"   3. Check README_PART2.txt from Part 1 for correct path\")\n",
    "else:\n",
    "    manifest_path = f\"{PART1_OUTPUT_DIR}/_COURSES/manifest.json\"\n",
    "    if not os.path.exists(manifest_path):\n",
    "        print(\"âš ï¸ WARNING: Doesn't look like a valid Part 1 output\")\n",
    "        print(\"   Missing: _COURSES/manifest.json\")\n",
    "    else:\n",
    "        print(\"âœ… Part 1 outputs found!\")\n",
    "        print(f\"   {PART1_OUTPUT_DIR}\")\n",
    "        \n",
    "        # Copy to local directory\n",
    "        print(\"\\nCopying Part 1 outputs to local directory...\")\n",
    "        print(\"(This may take several minutes)\")\n",
    "        \n",
    "        if os.path.exists(OUTPUT_DIR):\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "        shutil.copytree(PART1_OUTPUT_DIR, OUTPUT_DIR)\n",
    "        \n",
    "        # Count courses\n",
    "        import glob\n",
    "        courses = []\n",
    "        for patient_dir in glob.glob(f\"{OUTPUT_DIR}/*/\"):\n",
    "            patient_name = os.path.basename(patient_dir.rstrip('/'))\n",
    "            if patient_name.startswith('_') or patient_name.startswith('.'):\n",
    "                continue\n",
    "            for course_dir in glob.glob(f\"{patient_dir}/*/\"):\n",
    "                course_name = os.path.basename(course_dir.rstrip('/'))\n",
    "                if not course_name.startswith('_'):\n",
    "                    courses.append(f\"{patient_name}/{course_name}\")\n",
    "        \n",
    "        print(f\"\\nâœ… Copied! Found {len(courses)} course(s):\")\n",
    "        for c in courses[:5]:\n",
    "            print(f\"  - {c}\")\n",
    "        if len(courses) > 5:\n",
    "            print(f\"  ... and {len(courses) - 5} more\")\n",
    "\n",
    "# Create logs directory\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load DICOM root from Part 1 config\n",
    "part1_config = f\"{OUTPUT_DIR}/config_part1.yaml\"\n",
    "if os.path.exists(part1_config):\n",
    "    with open(part1_config, 'r') as f:\n",
    "        import re\n",
    "        content = f.read()\n",
    "        match = re.search(r'dicom_root:\\s*\"([^\"]+)\"', content)\n",
    "        if match:\n",
    "            DICOM_ROOT = match.group(1)\n",
    "            print(f\"\\nâœ… DICOM root from Part 1: {DICOM_ROOT}\")\n",
    "        else:\n",
    "            DICOM_ROOT = \"/content/drive/MyDrive/my_dicom_folder\"\n",
    "            print(f\"\\nâš ï¸ Using default DICOM root: {DICOM_ROOT}\")\n",
    "else:\n",
    "    DICOM_ROOT = \"/content/drive/MyDrive/my_dicom_folder\"\n",
    "    print(f\"\\nâš ï¸ No Part 1 config found, using default DICOM root\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Configuration Summary:\")\n",
    "print(f\"   Workers: {WORKERS}\")\n",
    "print(f\"   Radiomics: {'âœ… Enabled' if ENABLE_RADIOMICS else 'âŒ Disabled'}\")\n",
    "print(f\"   Robustness: {'âœ… Enabled' if ENABLE_ROBUSTNESS else 'âŒ Disabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£b Robustness Testing Configuration (Optional)\n",
    "\n",
    "Only relevant if `ENABLE_ROBUSTNESS = True` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustness testing configuration (if enabled)\n",
    "ROBUSTNESS_STRUCTURES = [\n",
    "    \"GTV*\", \"CTV*\", \"PTV*\",\n",
    "    \"urinary_bladder\", \"rectum\", \"prostate\"\n",
    "]\n",
    "ROBUSTNESS_INTENSITY = \"standard\"  # mild, standard, aggressive\n",
    "\n",
    "if ENABLE_ROBUSTNESS:\n",
    "    print(f\"Robustness Testing: {ROBUSTNESS_INTENSITY}\")\n",
    "    print(f\"Structures: {len(ROBUSTNESS_STRUCTURES)} patterns\")\n",
    "else:\n",
    "    print(\"Robustness testing disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6ï¸âƒ£ Generate Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml = f\"\"\"# RTpipeline Configuration - Part 2 (CPU Analysis)\n",
    "dicom_root: \"{DICOM_ROOT}\"\n",
    "output_dir: \"{OUTPUT_DIR}\"\n",
    "logs_dir: \"{LOGS_DIR}\"\n",
    "workers: {WORKERS}\n",
    "\n",
    "radiomics:\n",
    "  params_file: \"/content/rtpipeline/rtpipeline/radiomics_params.yaml\"\n",
    "  thread_limit: 4\n",
    "  skip_rois: [body, couchsurface, bones]\n",
    "  max_voxels: 1500000000\n",
    "  min_voxels: 10\n",
    "\n",
    "radiomics_robustness:\n",
    "  enabled: {str(ENABLE_ROBUSTNESS).lower()}\n",
    "\n",
    "custom_structures: \"custom_structures_pelvic.yaml\"\n",
    "\"\"\"\n",
    "\n",
    "config_path = \"/content/config_part2.yaml\"\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_yaml)\n",
    "\n",
    "print(f\"âœ… Configuration written to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Run Part 2 Pipeline\n",
    "\n",
    "This runs all CPU-based analysis:\n",
    "- DVH extraction\n",
    "- Radiomics (if enabled)\n",
    "- Robustness testing (if enabled)\n",
    "- Quality control\n",
    "- Results aggregation\n",
    "\n",
    "â±ï¸ **Time:** 10-60 minutes depending on dataset and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.environ['PATH'] = f\"/content/miniconda/bin:{os.environ.get('PATH', '')}\"\n",
    "os.chdir('/content/rtpipeline')\n",
    "\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"   RTpipeline Part 2: CPU Analysis\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"\\nProcessing steps (all CPU-based):\")\n",
    "print(\"  âœ“ DVH extraction\")\n",
    "if ENABLE_RADIOMICS:\n",
    "    print(\"  âœ“ Radiomics extraction\")\n",
    "if ENABLE_ROBUSTNESS:\n",
    "    print(\"  âœ“ Robustness testing\")\n",
    "print(\"  âœ“ Quality control\")\n",
    "print(\"  âœ“ Results aggregation\\n\")\n",
    "\n",
    "# Install Snakemake if needed\n",
    "try:\n",
    "    subprocess.run([\"conda\", \"run\", \"-n\", \"base\", \"snakemake\", \"--version\"],\n",
    "                   check=True, capture_output=True)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Installing Snakemake...\")\n",
    "    subprocess.run([\"conda\", \"install\", \"-n\", \"base\", \"-c\", \"conda-forge\",\n",
    "                    \"-c\", \"bioconda\", \"snakemake\", \"-y\", \"-q\"], check=True)\n",
    "    print(\"âœ… Snakemake installed\\n\")\n",
    "\n",
    "# Run Snakemake for all steps\n",
    "cmd = [\n",
    "    \"conda\", \"run\", \"-n\", \"base\", \"snakemake\",\n",
    "    \"--configfile\", \"/content/config_part2.yaml\",\n",
    "    \"--use-conda\",\n",
    "    \"--cores\", str(WORKERS),\n",
    "    \"--printshellcmds\",\n",
    "    \"--keep-going\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=False, text=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… Part 2 Complete!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nResults: {OUTPUT_DIR}/_RESULTS/\")\n",
    "else:\n",
    "    print(\"âš ï¸ Completed with some errors\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nCheck logs and results: {OUTPUT_DIR}/_RESULTS/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ View Results\n",
    "\n",
    "Load and preview the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "results_dir = f\"{OUTPUT_DIR}/_RESULTS\"\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    print(\"âš ï¸ Results directory not found\")\n",
    "else:\n",
    "    print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "    print(\"   Results Summary\")\n",
    "    print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "    \n",
    "    # List files\n",
    "    files = [f for f in os.listdir(results_dir) if f.endswith('.xlsx')]\n",
    "    print(f\"Generated {len(files)} result files:\\n\")\n",
    "    for f in files:\n",
    "        size_mb = os.path.getsize(os.path.join(results_dir, f)) / 1024 / 1024\n",
    "        print(f\"  âœ“ {f} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Load DVH\n",
    "    try:\n",
    "        dvh = pd.read_excel(os.path.join(results_dir, \"dvh_metrics.xlsx\"))\n",
    "        print(f\"\\nğŸ“Š DVH Metrics: {len(dvh)} rows\")\n",
    "        print(f\"   Top structures: {', '.join(dvh['Structure'].value_counts().head(5).index.tolist())}\")\n",
    "        globals()['dvh'] = dvh\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸ DVH load error: {e}\")\n",
    "    \n",
    "    # Load radiomics\n",
    "    if ENABLE_RADIOMICS:\n",
    "        try:\n",
    "            radiomics = pd.read_excel(os.path.join(results_dir, \"radiomics_ct.xlsx\"))\n",
    "            print(f\"\\nğŸ”¬ Radiomics: {len(radiomics)} rows, {len(radiomics.columns)} features\")\n",
    "            globals()['radiomics'] = radiomics\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ Radiomics load error: {e}\")\n",
    "    \n",
    "    # Load robustness\n",
    "    if ENABLE_ROBUSTNESS:\n",
    "        try:\n",
    "            rob = pd.read_excel(os.path.join(results_dir, \"radiomics_robustness_summary.xlsx\"),\n",
    "                               sheet_name='global_summary')\n",
    "            print(f\"\\nğŸ¯ Robustness: {len(rob)} features analyzed\")\n",
    "            print(f\"   Categories: {rob['robustness_label'].value_counts().to_dict()}\")\n",
    "            globals()['robustness_summary'] = rob\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ Robustness load error: {e}\")\n",
    "    \n",
    "    # Load metadata\n",
    "    try:\n",
    "        metadata = pd.read_excel(os.path.join(results_dir, \"case_metadata.xlsx\"))\n",
    "        print(f\"\\nğŸ“‹ Metadata: {metadata['PatientID'].nunique()} patients, {len(metadata)} courses\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸ Metadata load error: {e}\")\n",
    "    \n",
    "    print(\"\\nâœ… Results loaded into memory\")\n",
    "    print(\"   Access via: dvh, radiomics, robustness_summary, metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "if 'dvh' in globals():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Mean dose by structure\n",
    "    top_structures = dvh.groupby('Structure')['Dmean_Gy'].mean().sort_values(ascending=False).head(10)\n",
    "    top_structures.plot(kind='barh', ax=axes[0], color='steelblue')\n",
    "    axes[0].set_xlabel('Mean Dose (Gy)')\n",
    "    axes[0].set_title('Top 10 Structures by Mean Dose')\n",
    "    \n",
    "    # Volume distribution\n",
    "    dvh['ROI_Volume_cc'].hist(bins=50, ax=axes[1], color='coral', edgecolor='black')\n",
    "    axes[1].set_xlabel('ROI Volume (cc)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('ROI Volume Distribution')\n",
    "    axes[1].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"âœ… DVH visualizations\")\n",
    "else:\n",
    "    print(\"âš ï¸ No DVH data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Robustness Visualizations (if enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_ROBUSTNESS and 'robustness_summary' in globals():\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # ICC distribution\n",
    "    robustness_summary['icc'].hist(bins=50, ax=axes[0,0], color='steelblue', alpha=0.7)\n",
    "    axes[0,0].axvline(0.90, color='green', linestyle='--', label='Robust (â‰¥0.90)')\n",
    "    axes[0,0].set_xlabel('ICC')\n",
    "    axes[0,0].set_title('ICC Distribution')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # CoV distribution\n",
    "    robustness_summary[robustness_summary['cov_pct'] <= 100]['cov_pct'].hist(\n",
    "        bins=50, ax=axes[0,1], color='coral', alpha=0.7)\n",
    "    axes[0,1].axvline(10, color='green', linestyle='--', label='Robust (â‰¤10%)')\n",
    "    axes[0,1].set_xlabel('CoV (%)')\n",
    "    axes[0,1].set_title('CoV Distribution')\n",
    "    axes[0,1].legend()\n",
    "    \n",
    "    # Category distribution\n",
    "    robustness_summary['robustness_label'].value_counts().plot(\n",
    "        kind='bar', ax=axes[1,0], color=['green', 'orange', 'red'])\n",
    "    axes[1,0].set_xlabel('Category')\n",
    "    axes[1,0].set_title('Robustness Categories')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # ICC vs CoV scatter\n",
    "    color_map = {'robust': 'green', 'acceptable': 'orange', 'poor': 'red'}\n",
    "    for label, color in color_map.items():\n",
    "        data = robustness_summary[robustness_summary['robustness_label'] == label]\n",
    "        axes[1,1].scatter(data['icc'], data['cov_pct'], \n",
    "                         c=color, label=label, alpha=0.6, s=30)\n",
    "    axes[1,1].axvline(0.90, color='green', linestyle='--', alpha=0.5)\n",
    "    axes[1,1].axhline(10, color='green', linestyle='--', alpha=0.5)\n",
    "    axes[1,1].set_xlabel('ICC')\n",
    "    axes[1,1].set_ylabel('CoV (%)')\n",
    "    axes[1,1].set_title('ICC vs CoV')\n",
    "    axes[1,1].set_ylim([0, 100])\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Robustness Summary\")\n",
    "    print(\"=\"*50)\n",
    "    for label in ['robust', 'acceptable', 'poor']:\n",
    "        count = (robustness_summary['robustness_label'] == label).sum()\n",
    "        pct = 100 * count / len(robustness_summary)\n",
    "        print(f\"{label.capitalize()}: {count} ({pct:.1f}%)\")\n",
    "elif ENABLE_ROBUSTNESS:\n",
    "    print(\"âš ï¸ Robustness data not loaded\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Robustness testing not enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ Download Results as ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"Creating results archive...\"\n",
    "cd /content\n",
    "zip -r -q results.zip output/_RESULTS/\n",
    "echo \"âœ… Archive created: /content/results.zip\"\n",
    "ls -lh /content/results.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading results.zip...\")\n",
    "files.download('/content/results.zip')\n",
    "print(\"\\nâœ… Download started. Check your browser's downloads folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ Save Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "drive_results = f\"/content/drive/MyDrive/rtpipeline_results_{timestamp}\"\n",
    "\n",
    "print(f\"Saving results to Google Drive...\")\n",
    "print(f\"Destination: {drive_results}\")\n",
    "\n",
    "try:\n",
    "    shutil.copytree(f\"{OUTPUT_DIR}/_RESULTS\", drive_results)\n",
    "    \n",
    "    files = [f for f in os.listdir(drive_results) if f.endswith('.xlsx')]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ ALL DONE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nResults saved to: {drive_results}\")\n",
    "    print(f\"\\nSaved {len(files)} files:\")\n",
    "    for f in files:\n",
    "        print(f\"  âœ“ {f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ Pipeline Complete!\n",
    "\n",
    "**What you have:**\n",
    "- âœ… DVH metrics for all structures\n",
    "- âœ… Radiomic features (if enabled)\n",
    "- âœ… Robustness analysis (if enabled)\n",
    "- âœ… Quality control reports\n",
    "- âœ… Analysis-ready Excel files\n",
    "\n",
    "**ğŸ’° Cost Savings:**\n",
    "By splitting GPU (Part 1) and CPU (Part 2), you've optimized your Colab costs!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Resources\n",
    "\n",
    "- **Output Format Guide:** [output_format.md](https://github.com/kstawiski/rtpipeline/blob/main/output_format.md)\n",
    "- **Robustness Guide:** [RADIOMICS_ROBUSTNESS.md](https://github.com/kstawiski/rtpipeline/blob/main/RADIOMICS_ROBUSTNESS.md)\n",
    "- **Repository:** https://github.com/kstawiski/rtpipeline\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Version:** 2.0 (Part 2 - CPU Analysis)  \n",
    "**Compatible with:** rtpipeline v2.0+ as of November 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

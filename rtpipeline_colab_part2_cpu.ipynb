{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTpipeline on Google Colab - Part 2: CPU Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kstawiski/rtpipeline/blob/main/rtpipeline_colab_part2_cpu.ipynb)\n",
    "\n",
    "**\ud83d\udcb0 Cost Optimization:** This notebook runs on **CPU ONLY** (no GPU needed)!\n",
    "\n",
    "## What This Part Does\n",
    "\n",
    "\u2705 **Loads segmentations** from Part 1\n",
    "\u2705 **DVH extraction** (dose-volume histogram metrics)\n",
    "\u2705 **Radiomics features** (150+ texture/shape features)\n",
    "\u2705 **Robustness testing** (optional - feature stability)\n",
    "\u2705 **Aggregation and visualization**\n",
    "\u2705 **Downloadable results**\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Part 1 (GPU segmentation)\n",
    "- Part 1 outputs saved to Google Drive\n",
    "- **CPU runtime** (Runtime \u2192 Change runtime type \u2192 None/CPU)\n",
    "\n",
    "---\n",
    "\n",
    "**\u26a1 Quick Start:**\n",
    "1. Run cells 1-3 (setup)\n",
    "2. Mount Google Drive (cell 4)\n",
    "3. **UPDATE CONFIGURATION** (cell 5) - Point to Part 1 output folder\n",
    "4. Run remaining cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e3 Setup: Install Miniconda & System Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Installing System Dependencies ===\"\n",
    "apt-get update -qq\n",
    "apt-get install -y -qq dcm2niix pigz > /dev/null\n",
    "\n",
    "if [ ! -d \"/content/miniconda\" ]; then\n",
    "    echo -e \"\\n=== Installing Miniconda ===\"\n",
    "    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh\n",
    "    bash /tmp/miniconda.sh -b -p /content/miniconda\n",
    "    rm /tmp/miniconda.sh\n",
    "    echo \"\u2705 Miniconda installed\"\n",
    "else\n",
    "    echo \"\u2705 Miniconda already installed\"\n",
    "fi\n",
    "\n",
    "export PATH=\"/content/miniconda/bin:$PATH\"\n",
    "eval \"$(/content/miniconda/bin/conda shell.bash hook)\"\n",
    "conda init bash\n",
    "\n",
    "echo -e \"\\n\u2705 Setup complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\ufe0f\u20e3 Clone RTpipeline Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d \"/content/rtpipeline\" ]; then\n",
    "    echo \"Cloning rtpipeline repository...\"\n",
    "    git clone -q https://github.com/kstawiski/rtpipeline.git /content/rtpipeline\n",
    "    echo \"\u2705 Repository cloned\"\n",
    "else\n",
    "    echo \"\u2705 Repository already exists\"\n",
    "    cd /content/rtpipeline\n",
    "    git pull origin main\n",
    "    echo \"Repository updated\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\ufe0f\u20e3 Create Conda Environments\n",
    "\n",
    "Creates two environments (~5-10 minutes, only once per session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PATH=\"/content/miniconda/bin:$PATH\"\n",
    "eval \"$(/content/miniconda/bin/conda shell.bash hook)\"\n",
    "\n",
    "echo \"=== Accepting Anaconda Terms of Service ===\"\n",
    "conda config --set channel_priority flexible\n",
    "if ! conda tos accept --channel defaults 2>&1; then\n",
    "    echo \"\u26a0\ufe0f ToS acceptance failed or already accepted\"\n",
    "fi\n",
    "\n",
    "cd /content/rtpipeline\n",
    "\n",
    "if conda env list | grep -q \"^rtpipeline \"; then\n",
    "    echo \"\u2705 Environment 'rtpipeline' exists\"\n",
    "else\n",
    "    echo \"Creating 'rtpipeline' environment...\"\n",
    "    conda env create -f envs/rtpipeline.yaml -q\n",
    "    echo \"\u2705 Created\"\n",
    "fi\n",
    "\n",
    "if conda env list | grep -q \"^rtpipeline-radiomics \"; then\n",
    "    echo \"\u2705 Environment 'rtpipeline-radiomics' exists\"\n",
    "else\n",
    "    echo \"Creating 'rtpipeline-radiomics' environment...\"\n",
    "    conda env create -f envs/rtpipeline-radiomics.yaml -q\n",
    "    echo \"\u2705 Created\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"\u2705 Environments ready\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\ufe0f\u20e3 Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n\u2705 Google Drive mounted at /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \u2699\ufe0f CONFIGURATION - UPDATE THIS!\n",
    "\n",
    "## 5\ufe0f\u20e3 Configure Part 1 Output Path & Processing Options\n",
    "\n",
    "**\ud83d\udd34 REQUIRED:** Update `PART1_OUTPUT_DIR`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import multiprocessing\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# \ud83d\udd34 REQUIRED - Point to Part 1 output in Google Drive\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "PART1_OUTPUT_DIR = \"/content/drive/MyDrive/rtpipeline_part1_output_20250101_120000\"\n",
    "\n",
    "# Check README_PART2.txt from Part 1 for the exact path\n",
    "# Format: /content/drive/MyDrive/rtpipeline_part1_output_YYYYMMDD_HHMMSS\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Parallelism & Performance Settings\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "# Snakemake workers (course-level parallelism)\n",
    "# Google Colab CPU: Can use more workers than GPU version\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "WORKERS = min(CPU_COUNT, 8)  # Auto-detect, max 8 (4-8 recommended)\n",
    "\n",
    "# DVH extraction parallelism\n",
    "# Each course DVH extraction can use multiple threads\n",
    "DVH_THREADS_PER_COURSE = 2  # Threads for parallel DVH calculation (1-4 recommended)\n",
    "\n",
    "# Radiomics parallelism\n",
    "RADIOMICS_THREAD_LIMIT = 4  # Thread limit for PyRadiomics (2-6 recommended)\n",
    "RADIOMICS_SEQUENTIAL = False  # Set True if memory issues occur\n",
    "\n",
    "# Aggregation parallelism\n",
    "AGGREGATION_THREADS = \"auto\"  # \"auto\" or specific number (e.g., 4)\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Analysis Options\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "# Enable/disable analysis components\n",
    "ENABLE_DVH = True  # DVH metrics extraction\n",
    "ENABLE_RADIOMICS = True  # Radiomic feature extraction\n",
    "ENABLE_ROBUSTNESS = False  # Robustness testing (adds 10-30 min)\n",
    "ENABLE_QC = True  # Quality control metrics\n",
    "\n",
    "# Radiomics ROI filtering\n",
    "RADIOMICS_SKIP_ROIS = [\"body\", \"couchsurface\", \"bones\"]  # Skip these ROIs\n",
    "RADIOMICS_MAX_VOXELS = 1500000000  # Skip ROIs larger than this\n",
    "RADIOMICS_MIN_VOXELS = 10  # Skip ROIs smaller than this\n",
    "\n",
    "# Radiomics parameters file\n",
    "RADIOMICS_PARAMS_CT = \"/content/rtpipeline/rtpipeline/radiomics_params.yaml\"\n",
    "RADIOMICS_PARAMS_MR = \"/content/rtpipeline/rtpipeline/radiomics_params_mr.yaml\"\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Robustness Testing Configuration (if enabled)\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "ROBUSTNESS_STRUCTURES = [\n",
    "    \"GTV*\", \"CTV*\", \"PTV*\",\n",
    "    \"urinary_bladder\", \"rectum\", \"prostate\"\n",
    "]  # Wildcard patterns for structures to test\n",
    "\n",
    "ROBUSTNESS_INTENSITY = \"standard\"  # Options: \"mild\", \"standard\", \"aggressive\"\n",
    "\n",
    "# Perturbation parameters (standard preset)\n",
    "ROBUSTNESS_VOLUME_CHANGES = [-0.15, 0.0, 0.15]  # \u00b115% volume changes\n",
    "ROBUSTNESS_TRANSLATIONS_MM = 0.0  # 0 = disabled, 3.0 or 5.0 to enable\n",
    "ROBUSTNESS_NOISE_LEVELS = [0.0]  # [0.0, 10.0, 20.0] to test noise\n",
    "ROBUSTNESS_CONTOUR_REALIZATIONS = 0  # 0 = disabled, 2-3 to enable\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Custom Structures Configuration\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "CUSTOM_STRUCTURES_FILE = \"custom_structures_pelvic.yaml\"\n",
    "# Options: \"custom_structures_pelvic.yaml\", \"custom_structures_thorax.yaml\"\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Validation & Setup\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "OUTPUT_DIR = \"/content/output\"\n",
    "LOGS_DIR = \"/content/logs\"\n",
    "\n",
    "if not os.path.exists(PART1_OUTPUT_DIR):\n",
    "    print(\"\ud83d\udd34 ERROR: Part 1 output not found!\")\n",
    "    print(f\"   Path: {PART1_OUTPUT_DIR}\")\n",
    "    print(\"\\n   Please:\")\n",
    "    print(\"   1. Complete Part 1 first\")\n",
    "    print(\"   2. Update PART1_OUTPUT_DIR above\")\n",
    "    print(\"   3. Check README_PART2.txt from Part 1\")\n",
    "else:\n",
    "    manifest_path = f\"{PART1_OUTPUT_DIR}/_COURSES/manifest.json\"\n",
    "    if not os.path.exists(manifest_path):\n",
    "        print(\"\u26a0\ufe0f WARNING: Not a valid Part 1 output (missing manifest)\")\n",
    "    else:\n",
    "        print(\"\u2705 Part 1 outputs found\")\n",
    "        print(f\"   {PART1_OUTPUT_DIR}\")\n",
    "        \n",
    "        print(\"\\nCopying outputs to local directory...\")\n",
    "        if os.path.exists(OUTPUT_DIR):\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "        shutil.copytree(PART1_OUTPUT_DIR, OUTPUT_DIR)\n",
    "        \n",
    "        import glob\n",
    "        courses = []\n",
    "        for patient_dir in glob.glob(f\"{OUTPUT_DIR}/*/\"):\n",
    "            patient_name = os.path.basename(patient_dir.rstrip('/'))\n",
    "            if patient_name.startswith('_') or patient_name.startswith('.'):\n",
    "                continue\n",
    "            for course_dir in glob.glob(f\"{patient_dir}/*/\"):\n",
    "                course_name = os.path.basename(course_dir.rstrip('/'))\n",
    "                if not course_name.startswith('_'):\n",
    "                    courses.append(f\"{patient_name}/{course_name}\")\n",
    "        \n",
    "        print(f\"\\n\u2705 Copied! Found {len(courses)} course(s)\")\n",
    "        if courses:\n",
    "            for c in courses[:3]:\n",
    "                print(f\"  - {c}\")\n",
    "            if len(courses) > 3:\n",
    "                print(f\"  ... and {len(courses) - 3} more\")\n",
    "\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load DICOM root from Part 1 config\n",
    "part1_config = f\"{OUTPUT_DIR}/config_part1.yaml\"\n",
    "DICOM_ROOT = \"/content/drive/MyDrive/my_dicom_folder\"  # default\n",
    "if os.path.exists(part1_config):\n",
    "    with open(part1_config, 'r') as f:\n",
    "        try:\n",
    "            import yaml\n",
    "        except ImportError:\n",
    "            import subprocess as _subprocess\n",
    "            import sys as _sys\n",
    "            _subprocess.check_call([_sys.executable, '-m', 'pip', 'install', 'pyyaml'])\n",
    "            import yaml\n",
    "\n",
    "        try:\n",
    "            part1_data = yaml.safe_load(f) or {}\n",
    "        except yaml.YAMLError as e:\n",
    "            print(f\"\\n\u26a0\ufe0f Could not parse Part 1 config: {e}\")\n",
    "        else:\n",
    "            dicom_root_from_part1 = part1_data.get('dicom_root')\n",
    "            if dicom_root_from_part1:\n",
    "                DICOM_ROOT = dicom_root_from_part1\n",
    "                print(f\"\\n\u2705 DICOM root from Part 1: {DICOM_ROOT}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udccb Configuration Summary:\")\n",
    "print(f\"   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\")\n",
    "print(f\"   CPU cores: {CPU_COUNT}\")\n",
    "print(f\"   Snakemake workers: {WORKERS}\")\n",
    "print(f\"   Parallelism:\")\n",
    "print(f\"     \u2022 DVH threads/course: {DVH_THREADS_PER_COURSE}\")\n",
    "print(f\"     \u2022 Radiomics thread limit: {RADIOMICS_THREAD_LIMIT}\")\n",
    "print(f\"     \u2022 Radiomics sequential: {RADIOMICS_SEQUENTIAL}\")\n",
    "print(f\"     \u2022 Aggregation: {AGGREGATION_THREADS}\")\n",
    "print(f\"   Components:\")\n",
    "print(f\"     \u2022 DVH: {'\u2705' if ENABLE_DVH else '\u274c'}\")\n",
    "print(f\"     \u2022 Radiomics: {'\u2705' if ENABLE_RADIOMICS else '\u274c'}\")\n",
    "print(f\"     \u2022 Robustness: {'\u2705' if ENABLE_ROBUSTNESS else '\u274c'}\")\n",
    "print(f\"     \u2022 QC: {'\u2705' if ENABLE_QC else '\u274c'}\")\n",
    "print(f\"   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\")\n",
    "\n",
    "# Parallelism recommendations\n",
    "if WORKERS * RADIOMICS_THREAD_LIMIT > CPU_COUNT * 2:\n",
    "    print(f\"\\n\u26a0\ufe0f NOTE: Total thread usage may exceed CPU cores\")\n",
    "    print(f\"   Consider reducing WORKERS or RADIOMICS_THREAD_LIMIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6\ufe0f\u20e3 Generate Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import yaml\n",
    "except ImportError:\n",
    "    import subprocess as _subprocess\n",
    "    import sys as _sys\n",
    "    _subprocess.check_call([_sys.executable, '-m', 'pip', 'install', 'pyyaml'])\n",
    "    import yaml\n",
    "\n",
    "config_data = {\n",
    "    'dicom_root': DICOM_ROOT,\n",
    "    'output_dir': OUTPUT_DIR,\n",
    "    'logs_dir': LOGS_DIR,\n",
    "    'workers': WORKERS,\n",
    "    'dvh': {\n",
    "        'threads_per_course': DVH_THREADS_PER_COURSE\n",
    "    },\n",
    "    'radiomics': {\n",
    "        'sequential': bool(RADIOMICS_SEQUENTIAL),\n",
    "        'params_file': RADIOMICS_PARAMS_CT,\n",
    "        'mr_params_file': RADIOMICS_PARAMS_MR,\n",
    "        'thread_limit': RADIOMICS_THREAD_LIMIT,\n",
    "        'skip_rois': RADIOMICS_SKIP_ROIS,\n",
    "        'max_voxels': RADIOMICS_MAX_VOXELS,\n",
    "        'min_voxels': RADIOMICS_MIN_VOXELS\n",
    "    },\n",
    "    'radiomics_robustness': {\n",
    "        'enabled': bool(ENABLE_ROBUSTNESS),\n",
    "        'structures': ROBUSTNESS_STRUCTURES if ENABLE_ROBUSTNESS else [],\n",
    "        'intensity': ROBUSTNESS_INTENSITY,\n",
    "        'volume_changes': ROBUSTNESS_VOLUME_CHANGES if ENABLE_ROBUSTNESS else [],\n",
    "        'translations_mm': ROBUSTNESS_TRANSLATIONS_MM,\n",
    "        'noise_levels': ROBUSTNESS_NOISE_LEVELS if ENABLE_ROBUSTNESS else [],\n",
    "        'contour_realizations': ROBUSTNESS_CONTOUR_REALIZATIONS\n",
    "    },\n",
    "    'aggregation': {\n",
    "        'threads': AGGREGATION_THREADS\n",
    "    },\n",
    "    'custom_structures': CUSTOM_STRUCTURES_FILE,\n",
    "    'components': {\n",
    "        'dvh': bool(ENABLE_DVH),\n",
    "        'radiomics': bool(ENABLE_RADIOMICS),\n",
    "        'robustness': bool(ENABLE_ROBUSTNESS),\n",
    "        'qc': bool(ENABLE_QC)\n",
    "    }\n",
    "}\n",
    "\n",
    "config_path = '/content/config_part2.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write('# RTpipeline Configuration - Part 2 (CPU Analysis)\\n')\n",
    "    yaml.safe_dump(config_data, f, sort_keys=False)\n",
    "\n",
    "print(f\"\u2705 Configuration written to: {config_path}\")\n",
    "print(f\"\\nReview configuration: !cat {config_path}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\ufe0f\u20e3 Run Part 2 Pipeline\n",
    "\n",
    "\u23f1\ufe0f **Estimated Time:**\n",
    "- DVH only: 5-15 minutes\n",
    "- DVH + Radiomics: 20-45 minutes\n",
    "- DVH + Radiomics + Robustness: 30-90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "os.environ['PATH'] = f\"/content/miniconda/bin:{os.environ.get('PATH', '')}\"\n",
    "os.chdir('/content/rtpipeline')\n",
    "\n",
    "print(\"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\")\n",
    "print(\"   RTpipeline Part 2: CPU Analysis\")\n",
    "print(\"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\")\n",
    "print(\"\\n\u26a1 Processing:\")\n",
    "if ENABLE_DVH:\n",
    "    print(f\"   \u2713 DVH extraction ({DVH_THREADS_PER_COURSE} threads/course)\")\n",
    "if ENABLE_RADIOMICS:\n",
    "    print(f\"   \u2713 Radiomics (thread limit: {RADIOMICS_THREAD_LIMIT})\")\n",
    "if ENABLE_ROBUSTNESS:\n",
    "    print(f\"   \u2713 Robustness testing ({ROBUSTNESS_INTENSITY})\")\n",
    "if ENABLE_QC:\n",
    "    print(\"   \u2713 Quality control\")\n",
    "print(f\"   \u2713 Aggregation\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Install Snakemake\n",
    "try:\n",
    "    subprocess.run([\"conda\", \"run\", \"-n\", \"base\", \"snakemake\", \"--version\"],\n",
    "                   check=True, capture_output=True)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Installing Snakemake...\")\n",
    "    subprocess.run([\"conda\", \"install\", \"-n\", \"base\", \"-c\", \"conda-forge\",\n",
    "                    \"-c\", \"bioconda\", \"snakemake\", \"-y\", \"-q\"], check=True)\n",
    "    print(\"\u2705 Snakemake installed\\n\")\n",
    "\n",
    "# Run pipeline\n",
    "cmd = [\n",
    "    \"conda\", \"run\", \"-n\", \"base\", \"snakemake\",\n",
    "    \"--configfile\", \"/content/config_part2.yaml\",\n",
    "    \"--use-conda\",\n",
    "    \"--cores\", str(WORKERS),\n",
    "    \"--printshellcmds\",\n",
    "    \"--keep-going\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=False, text=True)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if result.returncode == 0:\n",
    "    print(\"\u2705 Part 2 Complete!\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f Completed with some errors\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total time: {total_time/60:.1f} minutes\")\n",
    "print(f\"\\nResults: {OUTPUT_DIR}/_RESULTS/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\ufe0f\u20e3 View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "results_dir = f\"{OUTPUT_DIR}/_RESULTS\"\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    print(\"\u26a0\ufe0f Results directory not found\")\n",
    "else:\n",
    "    print(\"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\")\n",
    "    print(\"   Results Summary\")\n",
    "    print(\"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\\n\")\n",
    "    \n",
    "    files = [f for f in os.listdir(results_dir) if f.endswith('.xlsx')]\n",
    "    print(f\"Generated {len(files)} files:\\n\")\n",
    "    for f in files:\n",
    "        size_mb = os.path.getsize(os.path.join(results_dir, f)) / 1024 / 1024\n",
    "        print(f\"  \u2713 {f} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Load results\n",
    "    try:\n",
    "        dvh = pd.read_excel(os.path.join(results_dir, \"dvh_metrics.xlsx\"))\n",
    "        print(f\"\\n\ud83d\udcca DVH: {len(dvh)} rows\")\n",
    "        print(f\"   Structures: {', '.join(dvh['Structure'].value_counts().head(5).index.tolist())}\")\n",
    "        globals()['dvh'] = dvh\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n\u26a0\ufe0f DVH metrics file not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\u26a0\ufe0f Error loading DVH metrics: {e}\")\n",
    "    \n",
    "    if ENABLE_RADIOMICS:\n",
    "        try:\n",
    "            radiomics = pd.read_excel(os.path.join(results_dir, \"radiomics_ct.xlsx\"))\n",
    "            print(f\"\\n\ud83d\udd2c Radiomics: {len(radiomics)} rows, {len(radiomics.columns)} features\")\n",
    "            globals()['radiomics'] = radiomics\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if ENABLE_ROBUSTNESS:\n",
    "        try:\n",
    "            rob = pd.read_excel(os.path.join(results_dir, \"radiomics_robustness_summary.xlsx\"),\n",
    "                               sheet_name='global_summary')\n",
    "            print(f\"\\n\ud83c\udfaf Robustness: {len(rob)} features\")\n",
    "            print(f\"   {rob['robustness_label'].value_counts().to_dict()}\")\n",
    "            globals()['robustness_summary'] = rob\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"\\n\u2705 Results loaded: dvh, radiomics, robustness_summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9\ufe0f\u20e3 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "if 'dvh' in globals():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    top_structures = dvh.groupby('Structure')['Dmean_Gy'].mean().sort_values(ascending=False).head(10)\n",
    "    top_structures.plot(kind='barh', ax=axes[0], color='steelblue')\n",
    "    axes[0].set_xlabel('Mean Dose (Gy)')\n",
    "    axes[0].set_title('Top 10 Structures by Mean Dose')\n",
    "    \n",
    "    dvh['ROI_Volume_cc'].hist(bins=50, ax=axes[1], color='coral', edgecolor='black')\n",
    "    axes[1].set_xlabel('ROI Volume (cc)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('ROI Volume Distribution')\n",
    "    axes[1].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\u2705 DVH visualizations\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No DVH data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd1f Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content\n",
    "zip -r -q results.zip output/_RESULTS/\n",
    "echo \"\u2705 Archive: /content/results.zip\"\n",
    "ls -lh /content/results.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('/content/results.zip')\n",
    "print(\"\\n\u2705 Download started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e31\ufe0f\u20e3 Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "drive_results = f\"/content/drive/MyDrive/rtpipeline_results_{timestamp}\"\n",
    "\n",
    "try:\n",
    "    shutil.copytree(f\"{OUTPUT_DIR}/_RESULTS\", drive_results)\n",
    "    files = [f for f in os.listdir(drive_results) if f.endswith('.xlsx')]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\ud83c\udf89 ALL DONE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nSaved to: {drive_results}\")\n",
    "    print(f\"\\n{len(files)} files:\")\n",
    "    for f in files:\n",
    "        print(f\"  \u2713 {f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\u26a0\ufe0f Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udf89 Complete!\n",
    "\n",
    "**What you have:**\n",
    "- \u2705 DVH metrics\n",
    "- \u2705 Radiomic features\n",
    "- \u2705 Robustness analysis (if enabled)\n",
    "- \u2705 Analysis-ready data\n",
    "\n",
    "**\ud83d\udcb0 Cost Savings:** GPU used only for Part 1 segmentation!\n",
    "\n",
    "---\n",
    "\n",
    "**Resources:**\n",
    "- [Output Format Guide](https://github.com/kstawiski/rtpipeline/blob/main/output_format.md)\n",
    "- [Robustness Guide](https://github.com/kstawiski/rtpipeline/blob/main/RADIOMICS_ROBUSTNESS.md)\n",
    "- [Repository](https://github.com/kstawiski/rtpipeline)\n",
    "\n",
    "**Version:** 2.0 (Part 2 - CPU Analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}